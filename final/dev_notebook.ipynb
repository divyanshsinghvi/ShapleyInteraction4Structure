{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af294e1d-0794-4a9a-b981-69ad7c9d4001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T21:49:27.958719Z",
     "iopub.status.busy": "2023-08-24T21:49:27.958532Z",
     "iopub.status.idle": "2023-08-24T21:49:29.569124Z",
     "shell.execute_reply": "2023-08-24T21:49:29.568072Z",
     "shell.execute_reply.started": "2023-08-24T21:49:27.958702Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dependencies..\n",
      "Seq Length: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing dependencies..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import scipy\n",
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "from scipy.linalg import norm \n",
    "import pandas as pd\n",
    "import os\n",
    "# from util import RegressionGame\n",
    "# from util_sparse import getShapleyProjection\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "# import shap\n",
    "# import llm_helper\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "if not os.path.exists('__dcache__'):\n",
    "    os.makedirs('__dcache__')\n",
    "\n",
    "# N = 6000\n",
    "# print(\"Explanation count: %s\" % N)\n",
    "# k = 100\n",
    "# print(\"SHAP sample count: %s\" % k)\n",
    "seq_len = 50\n",
    "print(\"Seq Length: %s\" % seq_len)\n",
    "\n",
    "# Setup\n",
    "np.random.seed(1)\n",
    "# model = llm_helper.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da144645-241a-4cde-991e-f73e335410db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d149b369-2ff7-4d2f-a42a-4cde9979fee4",
   "metadata": {},
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59cbc80a-210c-40ff-89aa-ce9da3dcc78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T21:49:29.571262Z",
     "iopub.status.busy": "2023-08-24T21:49:29.570852Z",
     "iopub.status.idle": "2023-08-24T21:49:41.862165Z",
     "shell.execute_reply": "2023-08-24T21:49:41.861318Z",
     "shell.execute_reply.started": "2023-08-24T21:49:29.571240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "cuda = True\n",
    "\n",
    "from transformers import BertForMaskedLM, BertTokenizerFast\n",
    "if cuda:\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased').cuda()\n",
    "else:\n",
    "    model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "# tokenizer.pad_token = tokenizer.unk_token\n",
    "# test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "test = pd.read_pickle('../mwe_tagger/wikitext_train_gpt.pkl')\n",
    "test['length'] = test['sentence'].str.split().str.len()\n",
    "test = test[~((test['weak_mwe'].str.len()==0) & (test['strong_mwe'].str.len()==0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e38b72-b014-4954-8199-dd25aaeb479c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T21:49:41.863349Z",
     "iopub.status.busy": "2023-08-24T21:49:41.863134Z",
     "iopub.status.idle": "2023-08-24T21:49:41.892636Z",
     "shell.execute_reply": "2023-08-24T21:49:41.891320Z",
     "shell.execute_reply.started": "2023-08-24T21:49:41.863330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e432386-5d54-47fe-9665-e47906d46de0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T09:44:42.849091Z",
     "iopub.status.busy": "2023-08-26T09:44:42.848842Z",
     "iopub.status.idle": "2023-08-26T09:44:44.764983Z",
     "shell.execute_reply": "2023-08-26T09:44:44.764158Z",
     "shell.execute_reply.started": "2023-08-26T09:44:42.849071Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                  | 0/58830 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video_game developed by Sega and Media .\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n",
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "and\n",
      "and\n",
      "and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                  | 0/58830 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[3.7533e-08, 3.9374e-08, 3.1163e-08,  ..., 2.5029e-08, 2.9318e-07,\n",
      "         2.6741e-09]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# num_cores = 10\n",
    "\n",
    "def get_prediction_softmax(model, X, masked_token):\n",
    "    abc = torch.argmax(model(X).logits[masked_token])\n",
    "    print(tokenizer.decode(abc))\n",
    "    if cuda:\n",
    "        return torch.softmax(model(X).logits[masked_token], dim=1)\n",
    "    else:\n",
    "        return scipy.special.softmax(model(X).logits[masked_token].detach().numpy(), axis=1)\n",
    "\n",
    "def interaction_value_di(model, X, tokens , masked_token):\n",
    "    token1, token2 = tokens\n",
    "    \n",
    "    # token_next = max(token1, token2) + 1\n",
    "    AB = get_prediction_softmax(model, X, masked_token)\n",
    "    X_t1 = X.clone()\n",
    "    X_t1[token1] = tokenizer.pad_token_id\n",
    "    A = get_prediction_softmax(model, X_t1, masked_token)\n",
    "    \n",
    "    X_t2 = X.clone()\n",
    "    X_t2[token1] = tokenizer.pad_token_id\n",
    "    B = get_prediction_softmax(model, X_t2, masked_token)\n",
    "\n",
    "    X_t12 = X.clone()\n",
    "    X_t12[token2] = tokenizer.pad_token_id\n",
    "    X_t12[token1] = tokenizer.pad_token_id\n",
    "    phi = get_prediction_softmax(model, X_t12, masked_token)\n",
    "\n",
    "    print(AB, A, B, phi)\n",
    "    val = AB - A - B + phi\n",
    "    print(val)\n",
    "    \n",
    "    if cuda:\n",
    "        val = torch.linalg.norm(val, dim=1).cpu()\n",
    "    else:\n",
    "        val = np.linalg.norm(val, axis=1)\n",
    "\n",
    "    if cuda:\n",
    "        return val.detach(), masked_token\n",
    "    else:\n",
    "        return val, token_next\n",
    "\n",
    "\n",
    "\n",
    "def mwe_distance_interaction(encoded_row, row, col, row_number):\n",
    "    iv_mwe = []\n",
    "    \n",
    "    mwes = row[col]\n",
    "    for mwe in mwes:\n",
    "\n",
    "        for i in range(len(mwe)):\n",
    "            for j in range(len(mwe)):\n",
    "                if i > j:\n",
    "                    if len([x for x in mwe if x >= seq_len]) > 0:\n",
    "                        continue\n",
    "\n",
    "                    for k in range(len(encoded_row)):\n",
    "                        if k != mwe[i] -1 and k!= mwe[j] - 1 and abs(k - max(mwe[i]-1, mwe[j]-1))<=8:\n",
    "                            og = encoded_row.clone()\n",
    "                            og[k] = tokenizer.mask_token_id\n",
    "                            og = og.reshape(-1,1)\n",
    "                            iv = interaction_value_di(model, og, [mwe[i]-1, mwe[j]-1], k)\n",
    "                            iv_mwe.append([iv, abs((mwe[i]-1-(mwe[j]-1))),mwe, row_number, i, j, k])\n",
    "\n",
    "    return iv_mwe\n",
    "\n",
    "weak_mwe_distance = []\n",
    "strong_mwe_distance = []\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    print(row['sentence'])\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    if len(row['weak_mwe']) != 0:\n",
    "        weak_mwe_distance.append(mwe_distance_interaction(abc, row, 'weak_mwe', row_number))\n",
    "    \n",
    "    if len(row['strong_mwe']) != 0:\n",
    "        strong_mwe_distance.append(mwe_distance_interaction(abc, row, 'strong_mwe', row_number))\n",
    "\n",
    "    break\n",
    "    del abc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e39abac4-9316-4025-bc4e-6ff665211d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T03:06:22.052485Z",
     "iopub.status.busy": "2023-08-26T03:06:22.052195Z",
     "iopub.status.idle": "2023-08-26T03:08:16.699406Z",
     "shell.execute_reply": "2023-08-26T03:08:16.698597Z",
     "shell.execute_reply.started": "2023-08-26T03:06:22.052465Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(strong_mwe_distance, open('test1.pkl','wb'))\n",
    "pickle.dump(weak_mwe_distance, open('test2.pkl','wb'))\n",
    "weak_mwe_distance = [y for x in weak_mwe_distance for y in x]\n",
    "strong_mwe_distance = [y for x in strong_mwe_distance for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "378dac16-785a-4529-8cef-0285b8fdcf01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T06:45:55.438639Z",
     "iopub.status.busy": "2023-08-26T06:45:55.438077Z",
     "iopub.status.idle": "2023-08-26T06:45:57.577223Z",
     "shell.execute_reply": "2023-08-26T06:45:57.576451Z",
     "shell.execute_reply.started": "2023-08-26T06:45:55.438613Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(weak_mwe_distance[1])\n",
    "\n",
    "strong_mwe_distance = pickle.load( open('test1.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9d9067d-eb2b-446f-8d71-7ca30235c81d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T06:46:08.079065Z",
     "iopub.status.busy": "2023-08-26T06:46:08.078310Z",
     "iopub.status.idle": "2023-08-26T06:46:08.099039Z",
     "shell.execute_reply": "2023-08-26T06:46:08.098148Z",
     "shell.execute_reply.started": "2023-08-26T06:46:08.079026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_mwe_distance[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25b3c9d0-6ee7-41c5-bd82-6fcaba5a150e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T03:09:39.852579Z",
     "iopub.status.busy": "2023-08-26T03:09:39.851866Z",
     "iopub.status.idle": "2023-08-26T03:11:29.940250Z",
     "shell.execute_reply": "2023-08-26T03:11:29.939400Z",
     "shell.execute_reply.started": "2023-08-26T03:09:39.852557Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token', 'pred_token']).to_pickle('weak_mwe_distance_3d_mlm.pkl')\n",
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token', 'pred_token']).to_pickle('strong_mwe_distance_3d_mlm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fc4a83a-40dc-4a87-a51e-bfd87700f957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T03:51:59.333875Z",
     "iopub.status.busy": "2023-08-26T03:51:59.333613Z",
     "iopub.status.idle": "2023-08-26T06:43:17.984063Z",
     "shell.execute_reply": "2023-08-26T06:43:17.983133Z",
     "shell.execute_reply.started": "2023-08-26T03:51:59.333856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Average Distance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                                                                | 85/58830 [2:51:18<1973:13:31, 120.92s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Fetching Average Distance...\")\n",
    "cuda = True\n",
    "\n",
    "\n",
    "def calculate_interaction(encoded_row, row, row_number):\n",
    "    interactions = []\n",
    "    encoded_len = len(encoded_row)\n",
    "    for j in range( min(seq_len, encoded_len)):\n",
    "        for k in range(j+1, min(seq_len, encoded_len, j+10)):\n",
    "            if j+k >= encoded_len:\n",
    "                continue\n",
    "            if encoded_row[j] == tokenizer.unk_token_id or encoded_row[k] == tokenizer.unk_token_id:\n",
    "                continue\n",
    "\n",
    "            for pred_ind in range(len(encoded_row)):\n",
    "                if pred_ind != j and pred_ind!= k and (abs(pred_ind - max(k, j))<=8 or abs(pred_ind - min(k, j))<=8):\n",
    "                    og = encoded_row.clone()\n",
    "                    og[pred_ind] = tokenizer.mask_token_id\n",
    "                    og = og.reshape(-1,1)\n",
    "                    iv = interaction_value_di(model, og, [j, k], pred_ind)\n",
    "                    interactions.append([iv, abs((j-k)), row_number, j, k, pred_ind])\n",
    "            \n",
    "            # iv = interaction_value_di(model, encoded_row, [j, k])\n",
    "            # interactions.append([iv, abs(k -j),row_number, [j,k]])\n",
    "    return interactions\n",
    "\n",
    "average_distance = []\n",
    "start_time =  datetime.datetime.now()\n",
    "# min_row = average_distance[-1][2]\n",
    "# print(min_row)\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    # if i%9 == 0 or i<=100:\n",
    "    # print(i, len(test), f'{i*100/len(test)}%', (datetime.datetime.now() - start_time).seconds)\n",
    "    # start_time = datetime.datetime.now()\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    \n",
    "    average_distance.extend(calculate_interaction(abc, row, row_number))\n",
    "    if row_number % 1000 == 0:\n",
    "        print(len(average_distance))\n",
    "\n",
    "        # if len(average_distance) >= 457902:\n",
    "        #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584b85a-0159-4ff7-b5a7-5419997adce0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.923945Z",
     "iopub.status.idle": "2023-08-24T21:56:38.924212Z",
     "shell.execute_reply": "2023-08-24T21:56:38.924104Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.924091Z"
    }
   },
   "outputs": [],
   "source": [
    "asdasdasd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e483ca-93dc-4903-912c-e9db286c64c2",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f68b9-de64-46ad-b985-22bf0bd9dec3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.925288Z",
     "iopub.status.idle": "2023-08-24T21:56:38.925559Z",
     "shell.execute_reply": "2023-08-24T21:56:38.925431Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.925419Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda = True\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "if cuda:\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "else:\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2', use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "# test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "test = pd.read_pickle('../mwe_tagger/wikitext_train_gpt.pkl')\n",
    "test['length'] = test['sentence'].str.split().str.len()\n",
    "test = test[~((test['weak_mwe'].str.len()==0) & (test['strong_mwe'].str.len()==0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80dc2a8-33f4-4de4-9d7d-ce7cd2447dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6f077-94e3-4be8-b66b-6fb387ff45bc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.926844Z",
     "iopub.status.idle": "2023-08-24T21:56:38.927099Z",
     "shell.execute_reply": "2023-08-24T21:56:38.926994Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.926982Z"
    }
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# num_cores = 10\n",
    "\n",
    "def get_prediction_softmax(model, X, token_next):\n",
    "    if cuda:\n",
    "        return torch.softmax(model(X).logits[token_next:], dim=1)\n",
    "    else:\n",
    "        return scipy.special.softmax(model(X).logits[token_next:].detach().numpy(), axis=1)\n",
    "\n",
    "def interaction_value_di(model, X, tokens):\n",
    "    token1, token2 = tokens\n",
    "    \n",
    "    token_next = max(token1, token2) + 1\n",
    "    AB = get_prediction_softmax(model, X, token_next)\n",
    "    \n",
    "    X_t1 = X.clone()\n",
    "    X_t1[token1] = tokenizer.unk_token_id\n",
    "    A = get_prediction_softmax(model, X_t1, token_next)\n",
    "    \n",
    "    X_t2 = X.clone()\n",
    "    X_t2[token2] = tokenizer.unk_token_id\n",
    "    B = get_prediction_softmax(model, X_t2, token_next)\n",
    "\n",
    "    X_t12 = X.clone()\n",
    "    X_t12[token2] = tokenizer.unk_token_id\n",
    "    X_t12[token1] = tokenizer.unk_token_id\n",
    "    phi = get_prediction_softmax(model, X_t12, token_next)\n",
    "    \n",
    "    val = AB - A - B + phi\n",
    "    if cuda:\n",
    "        val = torch.linalg.norm(val, dim=1).cpu()\n",
    "    else:\n",
    "        val = np.linalg.norm(val, axis=1)\n",
    "    \n",
    "    del X_t1, X_t2, X_t12,  AB, A, B, phi\n",
    "    if cuda:\n",
    "        return val.detach(), token_next\n",
    "    else:\n",
    "        return val, token_next\n",
    "\n",
    "def mwe_distance_interaction(encoded_row, row, col, row_number):\n",
    "    iv_mwe = []\n",
    "    # col = 'weak_mwe' | 'strong_mwe'\n",
    "    \n",
    "    mwes = row[col]\n",
    "    for mwe in mwes:\n",
    "\n",
    "        for i in range(len(mwe)):\n",
    "            for j in range(len(mwe)):\n",
    "                if i > j:\n",
    "                    if len([x for x in mwe if x >= seq_len]) > 0:\n",
    "                        continue\n",
    "                    \n",
    "                    iv = interaction_value_di(model, encoded_row, [mwe[i]-1, mwe[j]-1])\n",
    "                    iv_mwe.append([iv, abs((mwe[i]-1-(mwe[j]-1))),mwe, row_number, i, j])\n",
    "    # print(torch.cuda.memory_allocated()/(1024*1024*1024))\n",
    "    return iv_mwe\n",
    "\n",
    "weak_mwe_distance = []\n",
    "strong_mwe_distance = []\n",
    "\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "        # print(row_number, len(test), f'{row_number*100/len(test)}%')\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    # print(\"Start\",torch.cuda.memory_allocated()/(1024*1024*1024))\n",
    "    # weak_mwe_distance.extend(mwe_distance_interaction(abc, row, 'weak_mwe', row_number))\n",
    "    # strong_mwe_distance.extend(mwe_distance_interaction(abc, row, 'strong_mwe', row_number))\n",
    "    if len(row['weak_mwe']) != 0:\n",
    "        weak_mwe_distance.append(mwe_distance_interaction(abc, row, 'weak_mwe', row_number))\n",
    "    \n",
    "    if len(row['strong_mwe']) != 0:\n",
    "        strong_mwe_distance.append(mwe_distance_interaction(abc, row, 'strong_mwe', row_number))\n",
    "    \n",
    "    # print(torch.cuda.memory_allocated()/(1024*1024*1024))\n",
    "    del abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f621ce3-0846-456e-8f7d-f9788b80d8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55934a4b-e781-4db1-8c1e-0d97508aaa20",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.928225Z",
     "iopub.status.idle": "2023-08-24T21:56:38.928478Z",
     "shell.execute_reply": "2023-08-24T21:56:38.928371Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.928358Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(strong_mwe_distance, open('test1.pkl','wb'))\n",
    "pickle.dump(weak_mwe_distance, open('test2.pkl','wb'))\n",
    "weak_mwe_distance = [y for x in weak_mwe_distance for y in x]\n",
    "strong_mwe_distance = [y for x in strong_mwe_distance for y in x]\n",
    "pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token']).to_pickle('weak_mwe_distance_3d_full.pkl')\n",
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token']).to_pickle('strong_mwe_distance_3d_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478f6ae-f304-4949-95fe-83144894a395",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.929483Z",
     "iopub.status.idle": "2023-08-24T21:56:38.929735Z",
     "shell.execute_reply": "2023-08-24T21:56:38.929629Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.929616Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde2911-b39b-4af9-9c57-040d2e467520",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.930699Z",
     "iopub.status.idle": "2023-08-24T21:56:38.930977Z",
     "shell.execute_reply": "2023-08-24T21:56:38.930872Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.930859Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Fetching Average Distance...\")\n",
    "cuda = True\n",
    "\n",
    "\n",
    "def calculate_interaction(encoded_row, row, row_number):\n",
    "    interactions = []\n",
    "    encoded_len = len(encoded_row)\n",
    "    for j in range( min(seq_len, encoded_len)):\n",
    "        for k in range(j+1, min(seq_len, encoded_len, j+10)):\n",
    "            if j+k >= encoded_len:\n",
    "                continue\n",
    "            if encoded_row[j] == tokenizer.unk_token_id or encoded_row[k] == tokenizer.unk_token_id:\n",
    "                continue\n",
    "            \n",
    "            iv = interaction_value_di(model, encoded_row, [j, k])\n",
    "            interactions.append([iv, abs(k -j),row_number, [j,k]])\n",
    "    return interactions\n",
    "\n",
    "average_distance = []\n",
    "start_time =  datetime.datetime.now()\n",
    "# min_row = average_distance[-1][2]\n",
    "# print(min_row)\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    # if i%9 == 0 or i<=100:\n",
    "    # print(i, len(test), f'{i*100/len(test)}%', (datetime.datetime.now() - start_time).seconds)\n",
    "    # start_time = datetime.datetime.now()\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    \n",
    "    average_distance.extend(calculate_interaction(abc, row, row_number))\n",
    "    if row_number % 1000 == 0:\n",
    "        print(len(average_distance))\n",
    "\n",
    "        if len(average_distance) >= 457902:\n",
    "            break\n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "# \n",
    "# num_cores = 9\n",
    "# for x in range(0, len(test), 99):\n",
    "#     print(x, len(test), f'{100*x/len(test)}%')\n",
    "#     fabc =  lambda x : tokenizer(x, padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    \n",
    "#     average_distance.extend(Parallel(n_jobs=num_cores)(\n",
    "#         delayed(calculate_interaction)(fabc(row['sentence']), row, i) for i, row in tqdm(test[x:x+99].iterrows())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3989a8-a69f-4549-bd62-dd3ef802ab41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6829488-fe87-49e0-b606-a39640d7f393",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.932853Z",
     "iopub.status.idle": "2023-08-24T21:56:38.933199Z",
     "shell.execute_reply": "2023-08-24T21:56:38.933065Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.933051Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(average_distance, columns = ['I', 'posdis', 'row_number', 'word_pair']).to_pickle('average_distance_3d_full.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91405974-39af-486a-a013-6b2b4c313d57",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b2769-b5ee-46fc-b063-8ff994687038",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.934384Z",
     "iopub.status.idle": "2023-08-24T21:56:38.934727Z",
     "shell.execute_reply": "2023-08-24T21:56:38.934588Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.934574Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "a = np.unique([y[-1]-y[0] for x in test['_'].to_list() for y in x], return_counts=True)\n",
    "print({x:y for x,y in zip(a[0], a[1][::-1].cumsum()[::-1])})\n",
    "print(np.unique([z for x in test['_'].to_list() for y in x for z in y], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbd21c-dcc2-4148-9f5c-a9e78d80e7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbcc8062-e2f8-4fbc-88c9-40a582d4041d",
   "metadata": {},
   "source": [
    "# EXPERIMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7725b98f-ac0e-4530-84ca-33a07ba8e5f8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.936294Z",
     "iopub.status.idle": "2023-08-24T21:56:38.936612Z",
     "shell.execute_reply": "2023-08-24T21:56:38.936492Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.936478Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2', use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "test['length'] = test['sentence'].str.split().str.len()\n",
    "test = test[test['length'] > seq_len].copy().reset_index(drop=True)\n",
    "X = tokenizer(test['sentence'].to_list(), padding=True,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b37cae3-20d2-4c17-8ae0-49ab862120ca",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.937944Z",
     "iopub.status.idle": "2023-08-24T21:56:38.938274Z",
     "shell.execute_reply": "2023-08-24T21:56:38.938140Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.938126Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# num_cores = 10\n",
    "\n",
    "def get_prediction_softmax(model, X):\n",
    "    return scipy.special.softmax(model(X).logits[-1].detach().numpy())\n",
    "\n",
    "def interaction_value_di(model, X, tokens):\n",
    "    token1, token2 = tokens\n",
    "    AB = get_prediction_softmax(model, X)\n",
    "    \n",
    "    X_t1 = X.clone()\n",
    "    X_t1[token1] = tokenizer.unk_token_id\n",
    "    A = get_prediction_softmax(model, X_t1)\n",
    "    \n",
    "    X_t2 = X.clone()\n",
    "    X_t2[token2] = tokenizer.unk_token_id\n",
    "    B = get_prediction_softmax(model, X_t2)\n",
    "\n",
    "    \n",
    "    X_t12 = X.clone()\n",
    "    X_t12[token2] = tokenizer.unk_token_id\n",
    "    X_t12[token1] = tokenizer.unk_token_id\n",
    "    phi = get_prediction_softmax(model, X_t12)\n",
    "    \n",
    "    val = AB - A - B + phi\n",
    "    val = np.linalg.norm(val)\n",
    "    return val\n",
    "\n",
    "def mwe_distance_interaction(encoded_row, row, col):\n",
    "    iv_mwe = []\n",
    "    # col = 'weak_mwe' | 'strong_mwe'\n",
    "    mwes = row[col]\n",
    "    for mwe in mwes:\n",
    "\n",
    "        for i in range(len(mwe)):\n",
    "            for j in range(len(mwe)):\n",
    "                if i > j:\n",
    "                    if len([x for x in mwe if x >= seq_len]) > 0:\n",
    "                        continue\n",
    "                    iv = interaction_value_di(model, encoded_row, [mwe[i]-1, mwe[j]-1])\n",
    "                    iv_mwe.append([iv, abs((mwe[i]-1-(mwe[j]-1))),mwe])\n",
    "    return iv_mwe\n",
    "weak_mwe_distance = []\n",
    "strong_mwe_distance = []\n",
    "\n",
    "# weak_mwe_distance = Parallel(n_jobs=num_cores)(\n",
    "#     delayed(mwe_distance_interaction)(X[i], row, 'weak_mwe') for i, row in test.iterrows())\n",
    "\n",
    "# strong_mwe_distance = Parallel(n_jobs=num_cores)(\n",
    "#     delayed(mwe_distance_interaction)(X[i], row, 'strong_mwe') for i, row in test.iterrows())\n",
    "\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "    if i%100==0:\n",
    "        print(i, len(test), f'{i*100/len(test)}%')\n",
    "    weak_mwe_distance.extend(mwe_distance_interaction(X[i], row, 'weak_mwe'))\n",
    "    strong_mwe_distance.extend(mwe_distance_interaction(X[i], row, 'strong_mwe'))\n",
    "\n",
    "pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore']).to_pickle('weak_mwe_distance1.pkl')\n",
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore']).to_pickle('strong_mwe_distance1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd809d-0069-4808-96e3-d39aae242337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b85413-4a72-49bd-9108-e0c902b2a49e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.939495Z",
     "iopub.status.idle": "2023-08-24T21:56:38.939811Z",
     "shell.execute_reply": "2023-08-24T21:56:38.939677Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.939664Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Fetching Average Distance...\")\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def calculate_interaction(encoded_row, row):\n",
    "    interactions = []\n",
    "    for j in range( seq_len):\n",
    "        for k in range(j+1, seq_len):\n",
    "\n",
    "            if j+k >= seq_len:\n",
    "                continue\n",
    "            if encoded_row[j] == tokenizer.unk_token_id or encoded_row[k] == tokenizer.unk_token_id:\n",
    "                continue\n",
    "            \n",
    "            iv = interaction_value_di(model, encoded_row, [j, k])\n",
    "            interactions.append([iv, abs(k -j),[j,k]])\n",
    "    return interactions\n",
    "\n",
    "average_distance = []\n",
    "# start_time =  datetime.datetime.now()\n",
    "# for i, row in test.iterrows():\n",
    "#     # if i%9 == 0 or i<=100:\n",
    "#     print(i, len(test), f'{i*100/len(test)}%', (datetime.datetime.now() - start_time).seconds)\n",
    "#     start_time = datetime.datetime.now()\n",
    "#     average_distance.extend(calculate_interaction(X[i], row))\n",
    "\n",
    "num_cores = 9\n",
    "for x in range(0, len(test), 99):\n",
    "    print(x, len(test), f'{100*x/len(test)}%')\n",
    "    average_distance.extend(Parallel(n_jobs=num_cores)(\n",
    "        delayed(calculate_interaction)(X[i], row) for i, row in tqdm(test[x:x+99].iterrows())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79101d8-f90d-40ba-b007-e522fb779c68",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.940943Z",
     "iopub.status.idle": "2023-08-24T21:56:38.941209Z",
     "shell.execute_reply": "2023-08-24T21:56:38.941101Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.941088Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_dist = [item for sublist in average_distance for item in sublist]\n",
    "pd.DataFrame(avg_dist, columns = ['I', 'posdis', 'ignore']).to_pickle('average_distance1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297cd3b-ad2c-4670-912e-565d8ceb34e9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.942268Z",
     "iopub.status.idle": "2023-08-24T21:56:38.942517Z",
     "shell.execute_reply": "2023-08-24T21:56:38.942412Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.942400Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# avg_dist = [item for sublist in average_distance for item in sublist]\n",
    "\n",
    "def plot_mean(avg_path='average_distance.pkl', weak_path='weak_mwe_distance.pkl', strong_path='strong_mwe_distance.pkl'):\n",
    "    avg_dist = pd.read_pickle(avg_path)\n",
    "    avg_df = pd.DataFrame(avg_dist, columns = ['I', 'posdis', 'ignore']).groupby('posdis')['I'].agg( ['mean', 'count', 'std']).rename(columns = {'mean':'avg_mean', 'count':'avg_count', 'std':'avg_std'})\n",
    "    weak_mwe_distance = pd.read_pickle(weak_path)\n",
    "    weak_mwe_df = pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore']).groupby('posdis')['I'].agg( ['mean', 'count', 'std']).rename(columns = {'mean':'weak_mean', 'count':'weak_count', 'std':'weak_std'})\n",
    "    weak_mwe_df = weak_mwe_df.drop(0)\n",
    "    strong_mwe_distance = pd.read_pickle(strong_path)\n",
    "    strong_mwe_df = pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore']).groupby('posdis')['I'].agg( ['mean', 'count', 'std']).rename(columns = {'mean':'strong_mean', 'count':'strong_count', 'std':'strong_std'})\n",
    "    abc = pd.concat([avg_df, weak_mwe_df, strong_mwe_df], axis=1)\n",
    "    display(abc)\n",
    "    abc = abc[abc['weak_count'] >=50]\n",
    "    abc[['avg_mean', 'weak_mean']].plot()\n",
    "    plt.show()\n",
    "plot_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e62896-a71a-43cb-80ff-d91887fa8319",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.943897Z",
     "iopub.status.idle": "2023-08-24T21:56:38.944155Z",
     "shell.execute_reply": "2023-08-24T21:56:38.944046Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.944035Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boxplot_posdis(avg_path='average_distance.pkl', weak_path='weak_mwe_distance.pkl', strong_path='strong_mwe_distance.pkl'):\n",
    "    avg_dist = pd.read_pickle(avg_path)\n",
    "    weak_mwe_distance = pd.read_pickle(weak_path)\n",
    "    strong_mwe_distance = pd.read_pickle(strong_path)\n",
    "    \n",
    "    avg_df = pd.DataFrame(avg_dist, columns = ['I', 'posdis', 'ignore']).drop(columns = ['ignore']).assign(Location='avg')\n",
    "    weak_df = pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore']).drop(columns = ['ignore']).assign(Location='weak')\n",
    "    weak_df = weak_df[weak_df['posdis']!=0].copy()\n",
    "    strong_df = pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore']).drop(columns = ['ignore']).assign(Location='strong')\n",
    "    cdf = pd.concat([avg_df, weak_df])#, strong_df])    \n",
    "    cdf = cdf[cdf['posdis']<=5].copy()\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    ax = sns.boxplot(x=\"posdis\", y='I',hue=\"Location\", data=cdf)     #hue=\"Letter\",\n",
    "    plt.show()\n",
    "\n",
    "boxplot_posdis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef6dcf-f9cc-49c9-aac8-5f3028f00cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7f603-c90c-44aa-abdf-17d1a898a078",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.945688Z",
     "iopub.status.idle": "2023-08-24T21:56:38.946085Z",
     "shell.execute_reply": "2023-08-24T21:56:38.945944Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.945927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# avg_df.boxplot(column = ['I'], by = 'posdis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c53f1-8ec6-4f39-b60b-f528a61b49a6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.947568Z",
     "iopub.status.idle": "2023-08-24T21:56:38.948271Z",
     "shell.execute_reply": "2023-08-24T21:56:38.947796Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.947780Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc9087-e4a3-4587-82bc-e851a4b6b7fa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.949977Z",
     "iopub.status.idle": "2023-08-24T21:56:38.950296Z",
     "shell.execute_reply": "2023-08-24T21:56:38.950172Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.950158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model(X[0:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d853449-b783-4087-8d90-c4c0c413fde0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.951871Z",
     "iopub.status.idle": "2023-08-24T21:56:38.952156Z",
     "shell.execute_reply": "2023-08-24T21:56:38.952043Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.952030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "[x for x in testlist_text if 'Although he wrote' in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95911c8d-5b2c-4b78-a774-0eaaf4a905b0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.953091Z",
     "iopub.status.idle": "2023-08-24T21:56:38.953387Z",
     "shell.execute_reply": "2023-08-24T21:56:38.953265Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.953252Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_mode = 1 # [norm of softmax ]\n",
    "\n",
    "\n",
    "# TODO: Fix the prediction fn. Might have to incorporate\n",
    "#  target variable to get the logit for the target variable instead of max\n",
    "predict_fn = llm_helper.get_prediction_fn(model, pred_mode = pred_mode)\n",
    "\n",
    "\n",
    "\n",
    "torch.no_grad()\n",
    "\n",
    "obj = RegressionGame(X = X[0:k], y=None, function = predict_fn, transform = torch.as_tensor)\n",
    "\n",
    "X_samp = X[k:(N+k)]\n",
    "\n",
    "shapley_values = np.empty((0, X.shape[1]))\n",
    "partial_residuals = np.empty((0, X.shape[1]))\n",
    "games = np.empty((0, 2 ** X.shape[1]))\n",
    "\n",
    "print(\"SHape\")\n",
    "print(X.shape[1])\n",
    "\n",
    "print(\"  ..ok!\")\n",
    "print(\"Generating explanations..\")\n",
    "\n",
    "for i in range(0, N):\n",
    "    example_row = X_samp[i,:].reshape((1,X_samp.shape[1]))\n",
    "    game = obj.getKernelSHAPGame(example_row)\n",
    "    games = np.append(games, game.reshape((1,game.shape[0])), axis = 0)\n",
    "    results, residualGame, origGame = getShapleyProjection(game)\n",
    "    shapley_values = np.append(shapley_values,\n",
    "                               np.array([np.flip(results[-1])]), axis=0)\n",
    "    partial_residuals = np.append(partial_residuals,\n",
    "                                  np.array([np.flip(norm(residualGame, axis = 0)/norm(origGame, axis = 0))]), axis = 0)\n",
    "    print(\"%s/%s samples done.\" % (i+1, N))\n",
    "    \n",
    "\n",
    "    if i % 100 == 0:\n",
    "        pd.DataFrame(X_samp).to_csv('data/llm_input.csv')\n",
    "        pd.DataFrame(shapley_values).to_csv('data/llm_shapley_values.csv')\n",
    "        pd.DataFrame(partial_residuals).to_csv('data/llm_partial_residuals.csv')\n",
    "\n",
    "print(\" Explanations saved to data/llm_*.csv!\")\n",
    "\n",
    "pd.DataFrame(X_samp).to_csv('data/llm_input.csv')\n",
    "pd.DataFrame(shapley_values).to_csv('data/llm_shapley_values.csv')\n",
    "pd.DataFrame(partial_residuals).to_csv('data/llm_partial_residuals.csv')\n",
    "\n",
    "\"\"\"\n",
    "TODO: \n",
    "1. How to get base line features for the text generation process? \n",
    "2. What is the appropriate metric for shapley score. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22e10c-cfff-4263-bc32-f15b5e366605",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.954573Z",
     "iopub.status.idle": "2023-08-24T21:56:38.955099Z",
     "shell.execute_reply": "2023-08-24T21:56:38.954896Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.954871Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "partial_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85b61f-b7d2-4053-b597-712cdac20257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8404e0-d4f3-4fad-b020-58ad8f706e8f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.956792Z",
     "iopub.status.idle": "2023-08-24T21:56:38.957137Z",
     "shell.execute_reply": "2023-08-24T21:56:38.957001Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.956987Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict_fn = llm_helper.get_prediction_fn(model, pred_mode = 1)\n",
    "\n",
    "\n",
    "\n",
    "# torch.no_grad()\n",
    "\n",
    "\n",
    "# # obj = RegressionGame(X = X[0:k], y=y[0:k], function = predict_fn, transform = torch.as_tensor)\n",
    "# obj = RegressionGame(X = X[0:k], y=None, function = predict_fn, transform = torch.as_tensor)\n",
    "\n",
    "# X_samp = X[k:(N+k)]\n",
    "\n",
    "# shapley_values = np.empty((0, X.shape[1]))\n",
    "# partial_residuals = np.empty((0, X.shape[1]))\n",
    "# games = np.empty((0, 2 ** X.shape[1]))\n",
    "\n",
    "# print(\"SHape\")\n",
    "# print(X.shape[1])\n",
    "\n",
    "# print(\"  ..ok!\")\n",
    "# print(\"Generating explanations..\")\n",
    "\n",
    "# for i in range(0, N):\n",
    "#     example_row = X_samp[i,:].reshape((1,X_samp.shape[1]))\n",
    "#     game = obj.getKernelSHAPGame(example_row)\n",
    "#     games = np.append(games, game.reshape((1,game.shape[0])), axis = 0)\n",
    "#     results, residualGame, origGame = getShapleyProjection(game)\n",
    "#     shapley_values = np.append(shapley_values,\n",
    "#                                np.array([np.flip(results[-1])]), axis=0)\n",
    "#     partial_residuals = np.append(partial_residuals,\n",
    "#                                   np.array([np.flip(norm(residualGame, axis = 0)/norm(origGame, axis = 0))]), axis = 0)\n",
    "#     print(\"%s/%s samples done.\" % (i+1, N))\n",
    "\n",
    "# print(\" Explanations saved to data/llm_*.csv!\")\n",
    "\n",
    "# pd.DataFrame(X_samp).to_csv('data/llm_input.csv')\n",
    "# pd.DataFrame(shapley_values).to_csv('data/llm_shapley_values.csv')\n",
    "# pd.DataFrame(partial_residuals).to_csv('data/llm_partial_residuals.csv')\n",
    "\n",
    "# \"\"\"\n",
    "# TODO: \n",
    "# 1. How to get base line features for the text generation process? \n",
    "# 2. What is the appropriate metric for shapley score. \n",
    "# 3. issue here, check why I was not able to make k = 40. model is probably not able to take more than 25. Check\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbff028-32d9-4cbc-94d3-9574243e1d06",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.958822Z",
     "iopub.status.idle": "2023-08-24T21:56:38.959076Z",
     "shell.execute_reply": "2023-08-24T21:56:38.958970Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.958958Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1e48-e0a0-4692-8905-7a8322da0dc9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.960210Z",
     "iopub.status.idle": "2023-08-24T21:56:38.960466Z",
     "shell.execute_reply": "2023-08-24T21:56:38.960349Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.960338Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "partial_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9c1e8-b53f-4f3e-bc3c-4d579f6a6f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
