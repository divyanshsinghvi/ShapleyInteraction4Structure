{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af294e1d-0794-4a9a-b981-69ad7c9d4001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T16:33:10.062364Z",
     "iopub.status.busy": "2023-09-20T16:33:10.061872Z",
     "iopub.status.idle": "2023-09-20T16:33:13.049073Z",
     "shell.execute_reply": "2023-09-20T16:33:13.048194Z",
     "shell.execute_reply.started": "2023-09-20T16:33:10.062342Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dependencies..\n",
      "Seq Length: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing dependencies..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import scipy\n",
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "from scipy.linalg import norm \n",
    "import pandas as pd\n",
    "import os\n",
    "# from util import RegressionGame\n",
    "# from util_sparse import getShapleyProjection\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "# import shap\n",
    "# import llm_helper\n",
    "from scipy import special\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "if not os.path.exists('__dcache__'):\n",
    "    os.makedirs('__dcache__')\n",
    "\n",
    "# N = 6000\n",
    "# print(\"Explanation count: %s\" % N)\n",
    "# k = 100\n",
    "# print(\"SHAP sample count: %s\" % k)\n",
    "seq_len = 50\n",
    "print(\"Seq Length: %s\" % seq_len)\n",
    "\n",
    "# Setup\n",
    "np.random.seed(1)\n",
    "# model = llm_helper.get_model()\n",
    "cuda = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149b369-2ff7-4d2f-a42a-4cde9979fee4",
   "metadata": {},
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c4ec9e-c2e6-4338-a0b8-ef0063899a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T17:55:36.776107Z",
     "iopub.status.busy": "2023-09-20T17:55:36.775318Z",
     "iopub.status.idle": "2023-09-20T17:56:20.145034Z",
     "shell.execute_reply": "2023-09-20T17:56:20.144027Z",
     "shell.execute_reply.started": "2023-09-20T17:55:36.776084Z"
    }
   },
   "outputs": [],
   "source": [
    "import experiment_runner\n",
    "bert_experiment = experiment_runner.ExperimentRunner(cuda=cuda, seq_len=seq_len, model_name='bert')\n",
    "bert_experiment.prepare_data()\n",
    "bert_experiment.prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a4f04-a3aa-417e-b396-74c8dffbb8cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T17:58:40.359518Z",
     "iopub.status.busy": "2023-09-20T17:58:40.358771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▌                                                                                                                                                                | 1612/58830 [04:22<3:27:56,  4.59it/s]"
     ]
    }
   ],
   "source": [
    "bert_experiment.run_mwe_interactions()\n",
    "bert_experiment.run_avg_interactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2117e4-30fb-4f40-bba0-2b78ee0a7363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T16:33:13.050346Z",
     "iopub.status.busy": "2023-09-20T16:33:13.050061Z",
     "iopub.status.idle": "2023-09-20T16:33:55.495747Z",
     "shell.execute_reply": "2023-09-20T16:33:55.494978Z",
     "shell.execute_reply.started": "2023-09-20T16:33:13.050328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import BertForMaskedLM, BertTokenizerFast\n",
    "if cuda:\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased').cuda()\n",
    "else:\n",
    "    model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "test = pd.concat([pd.read_pickle(f'../mwe_tagger/bert_bert.pkl_{i}').drop(columns= ['syntactic_distance_idx_mapped', 'syntactic_distance_idx', 'lemmas', 'd', 'toks', 'tags']) for i in range(4)])\n",
    "test['length'] = test['sentence'].str.split().str.len()\n",
    "test = test[~((test['weak_mwe'].str.len()==0) & (test['strong_mwe'].str.len()==0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80331973-c44b-4e0c-a15b-67915c0da94c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T16:33:55.496555Z",
     "iopub.status.busy": "2023-09-20T16:33:55.496371Z",
     "iopub.status.idle": "2023-09-20T16:33:55.542702Z",
     "shell.execute_reply": "2023-09-20T16:33:55.541937Z",
     "shell.execute_reply.started": "2023-09-20T16:33:55.496538Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = test.drop(columns = ['syntactic_distance_idx', 'lemmas', 'd', 'toks', 'tags'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a2d6ed-f798-44d5-aab1-3bd2bad22326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T16:33:55.544815Z",
     "iopub.status.busy": "2023-09-20T16:33:55.543981Z",
     "iopub.status.idle": "2023-09-20T17:51:01.371187Z",
     "shell.execute_reply": "2023-09-20T17:51:01.369349Z",
     "shell.execute_reply.started": "2023-09-20T16:33:55.544780Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                        | 6/58830 [00:02<4:21:39,  3.75it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████                                                                                 | 29432/58830 [1:17:04<1:16:59,  6.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m     abc \u001b[38;5;241m=\u001b[39m abc\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweak_mwe\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 68\u001b[0m     weak_mwe_distance\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmwe_distance_interaction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweak_mwe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_number\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrong_mwe\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     71\u001b[0m     strong_mwe_distance\u001b[38;5;241m.\u001b[39mappend(mwe_distance_interaction(abc, row, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrong_mwe\u001b[39m\u001b[38;5;124m'\u001b[39m, row_number))\n",
      "Cell \u001b[0;32mIn[4], line 54\u001b[0m, in \u001b[0;36mmwe_distance_interaction\u001b[0;34m(encoded_row, row, col, row_number)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mwe \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m seq_len]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     53\u001b[0m                     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m                 iv \u001b[38;5;241m=\u001b[39m \u001b[43minteraction_value_di\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmwe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmwe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m                 iv_mwe\u001b[38;5;241m.\u001b[39mappend([iv, \u001b[38;5;28mabs\u001b[39m((mwe[i]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m(mwe[j]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))),mwe, row_number, i, j])\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m iv_mwe\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36minteraction_value_di\u001b[0;34m(model, X, tokens)\u001b[0m\n\u001b[1;32m     12\u001b[0m AB \u001b[38;5;241m=\u001b[39m get_prediction_softmax(model, X)\n\u001b[1;32m     13\u001b[0m X_t1 \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m---> 14\u001b[0m X_t1[\u001b[38;5;241m0\u001b[39m, token1] \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id\n\u001b[1;32m     15\u001b[0m A \u001b[38;5;241m=\u001b[39m get_prediction_softmax(model, X_t1)\n\u001b[1;32m     17\u001b[0m X_t2 \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mclone()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_prediction_softmax(model, X):\n",
    "    logits = model(X).logits\n",
    "    abc =  logits[0, :, :].softmax(dim=-1)\n",
    "    if not cuda:\n",
    "        return abc.detach().numpy()\n",
    "    else:\n",
    "        return abc\n",
    "    \n",
    "def interaction_value_di(model, X, tokens):\n",
    "    token1, token2 = tokens\n",
    "    # token_next = max(token1, token2) + 1\n",
    "    AB = get_prediction_softmax(model, X)\n",
    "    X_t1 = X.clone()\n",
    "    X_t1[0, token1] = tokenizer.pad_token_id\n",
    "    A = get_prediction_softmax(model, X_t1)\n",
    "    \n",
    "    X_t2 = X.clone()\n",
    "    X_t2[0,token1] = tokenizer.pad_token_id\n",
    "    B = get_prediction_softmax(model, X_t2)\n",
    "\n",
    "    X_t12 = X.clone()\n",
    "    X_t12[0,token2] = tokenizer.pad_token_id\n",
    "    X_t12[0,token1] = tokenizer.pad_token_id\n",
    "    phi = get_prediction_softmax(model, X_t12)\n",
    "\n",
    "    # print(AB, A, B, phi)\n",
    "    val = AB - A - B + phi\n",
    "    \n",
    "    if cuda:\n",
    "        val = torch.divide(torch.linalg.norm(val, dim=1), torch.linalg.norm(AB, dim=1)).cpu()\n",
    "    else:\n",
    "        val = np.linalg.norm(val, axis=1)\n",
    "\n",
    "    if cuda:\n",
    "        return val.detach()\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "\n",
    "\n",
    "def mwe_distance_interaction(encoded_row, row, col, row_number):\n",
    "\n",
    "    iv_mwe = []\n",
    "    \n",
    "    mwes = row[col]\n",
    "    encoded_row = encoded_row.reshape(1, -1)\n",
    "    for mwe in mwes:\n",
    "\n",
    "        for i in range(len(mwe)):\n",
    "            for j in range(len(mwe)):\n",
    "                if i > j:\n",
    "                    if len([x for x in mwe if x >= seq_len]) > 0:\n",
    "                        continue\n",
    "                    iv = interaction_value_di(model, encoded_row, [mwe[i]-1, mwe[j]-1])\n",
    "                    iv_mwe.append([iv, abs((mwe[i]-1-(mwe[j]-1))),mwe, row_number, i, j])\n",
    "                    \n",
    "    return iv_mwe\n",
    "\n",
    "weak_mwe_distance = []\n",
    "strong_mwe_distance = []\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    if len(row['weak_mwe']) != 0:\n",
    "        weak_mwe_distance.append(mwe_distance_interaction(abc, row, 'weak_mwe', row_number))\n",
    "    \n",
    "    if len(row['strong_mwe']) != 0:\n",
    "        strong_mwe_distance.append(mwe_distance_interaction(abc, row, 'strong_mwe', row_number))\n",
    "    del abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39abac4-9316-4025-bc4e-6ff665211d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T17:52:30.054580Z",
     "iopub.status.busy": "2023-09-20T17:52:30.053787Z",
     "iopub.status.idle": "2023-09-20T17:52:35.716687Z",
     "shell.execute_reply": "2023-09-20T17:52:35.715954Z",
     "shell.execute_reply.started": "2023-09-20T17:52:30.054551Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(strong_mwe_distance, open('test_bert_exp3_strong.pkl','wb'))\n",
    "# pickle.dump(weak_mwe_distance, open('test_bert_exp3_weak.pkl','wb'))\n",
    "weak_mwe_distance = [y for x in weak_mwe_distance for y in x]\n",
    "strong_mwe_distance = [y for x in strong_mwe_distance for y in x]\n",
    "\n",
    "pd.DataFrame(weak_mwe_distance, columns = ['tensor', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token']).to_pickle('weak_mwe_distance_3d_mlm_run2.pkl')\n",
    "pd.DataFrame(strong_mwe_distance, columns = ['tensor', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token']).to_pickle('strong_mwe_distance_3d_mlm_run2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c161fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T03:51:59.333875Z",
     "iopub.status.busy": "2023-08-26T03:51:59.333613Z",
     "iopub.status.idle": "2023-08-26T06:43:17.984063Z",
     "shell.execute_reply": "2023-08-26T06:43:17.983133Z",
     "shell.execute_reply.started": "2023-08-26T03:51:59.333856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Average Distance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                     | 526/58830 [41:51<81:44:43,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                                | 1640/58830 [2:25:12<42:10:49,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                              | 2193/58830 [3:13:39<118:16:19,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▊                                                                                              | 2846/58830 [4:12:57<93:10:59,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▌                                                                                            | 3916/58830 [5:57:24<66:26:05,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▌                                                                                           | 4495/58830 [6:57:17<67:39:22,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▍                                                                                          | 5011/58830 [7:38:30<63:43:19,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████████▏                                                                                      | 6694/58830 [10:08:51<71:10:48,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████████                                                                                      | 7260/58830 [10:56:31<45:00:34,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▋                                                                                | 10154/58830 [15:33:03<80:20:54,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1361908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▋                                                                               | 10738/58830 [16:30:38<69:01:25,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1438296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████▋                                                                            | 12527/58830 [19:09:40<74:56:29,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████                                                                          | 13482/58830 [20:41:36<102:10:14,  8.11s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Fetching Average Distance...\")\n",
    "cuda = True\n",
    "\n",
    "\n",
    "def calculate_interaction(encoded_row, row, row_number):\n",
    "    interactions = []\n",
    "    encoded_len = len(encoded_row)\n",
    "    for j in range( min(seq_len, encoded_len)):\n",
    "        for k in range(j+1, min(seq_len, encoded_len, j+10)):\n",
    "            if j+k >= encoded_len:\n",
    "                continue\n",
    "            if encoded_row[j] == tokenizer.unk_token_id or encoded_row[k] == tokenizer.unk_token_id:\n",
    "                continue\n",
    "\n",
    "#             for pred_ind in range(len(encoded_row)):\n",
    "#                 if pred_ind != j and pred_ind!= k and (abs(pred_ind - max(k, j))<=10 or abs(pred_ind - min(k, j))<=10):\n",
    "            og = encoded_row.clone()\n",
    "#             og[pred_ind] = tokenizer.mask_token_id\n",
    "            og = og.reshape(1, -1)\n",
    "            iv = interaction_value_di(model, og, [j, k])\n",
    "            interactions.append([iv, abs((j-k)), row_number, j, k])\n",
    "            \n",
    "            # iv = interaction_value_di(model, encoded_row, [j, k])\n",
    "            # interactions.append([iv, abs(k -j),row_number, [j,k]])\n",
    "    return interactions\n",
    "\n",
    "average_distance = []\n",
    "start_time =  datetime.datetime.now()\n",
    "# min_row = average_distance[-1][2]\n",
    "# print(min_row)\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    \n",
    "    average_distance.extend(calculate_interaction(abc, row, row_number))\n",
    "    if row_number % 1000 == 0:\n",
    "        print(len(average_distance))\n",
    "        pickle.dump(average_distance, open('average_distance_bert_exp3.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584b85a-0159-4ff7-b5a7-5419997adce0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.923945Z",
     "iopub.status.idle": "2023-08-24T21:56:38.924212Z",
     "shell.execute_reply": "2023-08-24T21:56:38.924104Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.924091Z"
    }
   },
   "outputs": [],
   "source": [
    "asdasdasd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e483ca-93dc-4903-912c-e9db286c64c2",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77f68b9-de64-46ad-b985-22bf0bd9dec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T05:25:24.454950Z",
     "iopub.status.busy": "2023-09-20T05:25:24.454306Z",
     "iopub.status.idle": "2023-09-20T05:26:28.265156Z",
     "shell.execute_reply": "2023-09-20T05:26:28.264251Z",
     "shell.execute_reply.started": "2023-09-20T05:25:24.454931Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cuda = True\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "if cuda:\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "else:\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2', use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "# test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "\n",
    "test = pd.concat([pd.read_pickle(f'../mwe_tagger/gpt_gpt.pkl_{i}').drop(columns= ['syntactic_distance_idx_mapped', 'syntactic_distance_idx', 'lemmas', 'd', 'toks', 'tags']) for i in range(4)])\n",
    "# test = pd.read_pickle('../mwe_tagger/wikitext_train_gpt.pkl')\n",
    "test['length'] = test['sentence'].str.split().str.len()\n",
    "test = test[~((test['weak_mwe'].str.len()==0) & (test['strong_mwe'].str.len()==0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80dc2a8-33f4-4de4-9d7d-ce7cd2447dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc6f077-94e3-4be8-b66b-6fb387ff45bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T05:26:58.882041Z",
     "iopub.status.busy": "2023-09-20T05:26:58.881321Z",
     "iopub.status.idle": "2023-09-20T07:59:16.310082Z",
     "shell.execute_reply": "2023-09-20T07:59:16.309102Z",
     "shell.execute_reply.started": "2023-09-20T05:26:58.882020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 58830/58830 [2:32:17<00:00,  6.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# num_cores = 10\n",
    "\n",
    "def get_prediction_softmax(model, X, token_next):\n",
    "    if cuda:\n",
    "        return torch.softmax(model(X).logits[token_next:], dim=1)\n",
    "    else:\n",
    "        return scipy.special.softmax(model(X).logits[token_next:].detach().numpy(), axis=1)\n",
    "\n",
    "def interaction_value_di(model, X, tokens):\n",
    "    token1, token2 = tokens\n",
    "    \n",
    "    token_next = max(token1, token2) + 1\n",
    "    AB = get_prediction_softmax(model, X, token_next)\n",
    "    \n",
    "    X_t1 = X.clone()\n",
    "    X_t1[token1] = tokenizer.unk_token_id\n",
    "    A = get_prediction_softmax(model, X_t1, token_next)\n",
    "    \n",
    "    X_t2 = X.clone()\n",
    "    X_t2[token2] = tokenizer.unk_token_id\n",
    "    B = get_prediction_softmax(model, X_t2, token_next)\n",
    "\n",
    "    X_t12 = X.clone()\n",
    "    X_t12[token2] = tokenizer.unk_token_id\n",
    "    X_t12[token1] = tokenizer.unk_token_id\n",
    "    phi = get_prediction_softmax(model, X_t12, token_next)\n",
    "    \n",
    "    val = AB - A - B + phi\n",
    "    if cuda:\n",
    "        val = torch.linalg.norm(val, dim=1).cpu()\n",
    "    else:\n",
    "        val = np.linalg.norm(val, axis=1)\n",
    "    \n",
    "    del X_t1, X_t2, X_t12,  AB, A, B, phi\n",
    "    if cuda:\n",
    "        return val.detach(), token_next\n",
    "    else:\n",
    "        return val, token_next\n",
    "\n",
    "def mwe_distance_interaction(encoded_row, row, col, row_number):\n",
    "    iv_mwe = []\n",
    "    # col = 'weak_mwe' | 'strong_mwe'\n",
    "    \n",
    "    mwes = row[col]\n",
    "    for mwe in mwes:\n",
    "\n",
    "        for i in range(len(mwe)):\n",
    "            for j in range(len(mwe)):\n",
    "                if i > j:\n",
    "                    if len([x for x in mwe if x >= seq_len]) > 0:\n",
    "                        continue\n",
    "                    \n",
    "                    iv = interaction_value_di(model, encoded_row, [mwe[i]-1, mwe[j]-1])\n",
    "                    iv_mwe.append([iv, abs((mwe[i]-1-(mwe[j]-1))),mwe, row_number, i, j])\n",
    "    return iv_mwe\n",
    "\n",
    "weak_mwe_distance = []\n",
    "strong_mwe_distance = []\n",
    "\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    # Tokenize each sentence with no padding and truncate if seq_len < tokenized sentence length\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    if len(row['weak_mwe']) != 0:\n",
    "        weak_mwe_distance.append(mwe_distance_interaction(abc, row, 'weak_mwe', row_number))\n",
    "    \n",
    "    if len(row['strong_mwe']) != 0:\n",
    "        strong_mwe_distance.append(mwe_distance_interaction(abc, row, 'strong_mwe', row_number))\n",
    "    \n",
    "    del abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f621ce3-0846-456e-8f7d-f9788b80d8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55934a4b-e781-4db1-8c1e-0d97508aaa20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T07:59:16.312288Z",
     "iopub.status.busy": "2023-09-20T07:59:16.312008Z",
     "iopub.status.idle": "2023-09-20T07:59:32.712662Z",
     "shell.execute_reply": "2023-09-20T07:59:32.711906Z",
     "shell.execute_reply.started": "2023-09-20T07:59:16.312250Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(strong_mwe_distance, open('test1.pkl','wb'))\n",
    "pickle.dump(weak_mwe_distance, open('test2.pkl','wb'))\n",
    "weak_mwe_distance = [y for x in weak_mwe_distance for y in x]\n",
    "strong_mwe_distance = [y for x in strong_mwe_distance for y in x]\n",
    "pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token']).to_pickle('weak_mwe_distance_3d_full_run2.pkl')\n",
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token']).to_pickle('strong_mwe_distance_3d_full_run2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478f6ae-f304-4949-95fe-83144894a395",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.929483Z",
     "iopub.status.idle": "2023-08-24T21:56:38.929735Z",
     "shell.execute_reply": "2023-08-24T21:56:38.929629Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.929616Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde2911-b39b-4af9-9c57-040d2e467520",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.930699Z",
     "iopub.status.idle": "2023-08-24T21:56:38.930977Z",
     "shell.execute_reply": "2023-08-24T21:56:38.930872Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.930859Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Fetching Average Distance...\")\n",
    "cuda = True\n",
    "\n",
    "\n",
    "def calculate_interaction(encoded_row, row, row_number):\n",
    "    interactions = []\n",
    "    encoded_len = len(encoded_row)\n",
    "    for j in range( min(seq_len, encoded_len)):\n",
    "        for k in range(j+1, min(seq_len, encoded_len, j+10)):\n",
    "            if j+k >= encoded_len:\n",
    "                continue\n",
    "            if encoded_row[j] == tokenizer.unk_token_id or encoded_row[k] == tokenizer.unk_token_id:\n",
    "                continue\n",
    "            \n",
    "            iv = interaction_value_di(model, encoded_row, [j, k])\n",
    "            interactions.append([iv, abs(k -j),row_number, [j,k]])\n",
    "    return interactions\n",
    "\n",
    "average_distance = []\n",
    "start_time =  datetime.datetime.now()\n",
    "# min_row = average_distance[-1][2]\n",
    "# print(min_row)\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    # if i%9 == 0 or i<=100:\n",
    "    # print(i, len(test), f'{i*100/len(test)}%', (datetime.datetime.now() - start_time).seconds)\n",
    "    # start_time = datetime.datetime.now()\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    \n",
    "    average_distance.extend(calculate_interaction(abc, row, row_number))\n",
    "    if row_number % 1000 == 0:\n",
    "        print(len(average_distance))\n",
    "\n",
    "        if len(average_distance) >= 457902:\n",
    "            break\n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "# \n",
    "# num_cores = 9\n",
    "# for x in range(0, len(test), 99):\n",
    "#     print(x, len(test), f'{100*x/len(test)}%')\n",
    "#     fabc =  lambda x : tokenizer(x, padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    \n",
    "#     average_distance.extend(Parallel(n_jobs=num_cores)(\n",
    "#         delayed(calculate_interaction)(fabc(row['sentence']), row, i) for i, row in tqdm(test[x:x+99].iterrows())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3989a8-a69f-4549-bd62-dd3ef802ab41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6829488-fe87-49e0-b606-a39640d7f393",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.932853Z",
     "iopub.status.idle": "2023-08-24T21:56:38.933199Z",
     "shell.execute_reply": "2023-08-24T21:56:38.933065Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.933051Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(average_distance, columns = ['I', 'posdis', 'row_number', 'word_pair']).to_pickle('average_distance_3d_full.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91405974-39af-486a-a013-6b2b4c313d57",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b2769-b5ee-46fc-b063-8ff994687038",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.934384Z",
     "iopub.status.idle": "2023-08-24T21:56:38.934727Z",
     "shell.execute_reply": "2023-08-24T21:56:38.934588Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.934574Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "a = np.unique([y[-1]-y[0] for x in test['_'].to_list() for y in x], return_counts=True)\n",
    "print({x:y for x,y in zip(a[0], a[1][::-1].cumsum()[::-1])})\n",
    "print(np.unique([z for x in test['_'].to_list() for y in x for z in y], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbd21c-dcc2-4148-9f5c-a9e78d80e7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbcc8062-e2f8-4fbc-88c9-40a582d4041d",
   "metadata": {},
   "source": [
    "# EXPERIMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7725b98f-ac0e-4530-84ca-33a07ba8e5f8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.936294Z",
     "iopub.status.idle": "2023-08-24T21:56:38.936612Z",
     "shell.execute_reply": "2023-08-24T21:56:38.936492Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.936478Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2', use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "test['length'] = test['sentence'].str.split().str.len()\n",
    "test = test[test['length'] > seq_len].copy().reset_index(drop=True)\n",
    "X = tokenizer(test['sentence'].to_list(), padding=True,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b37cae3-20d2-4c17-8ae0-49ab862120ca",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.937944Z",
     "iopub.status.idle": "2023-08-24T21:56:38.938274Z",
     "shell.execute_reply": "2023-08-24T21:56:38.938140Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.938126Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# num_cores = 10\n",
    "\n",
    "def get_prediction_softmax(model, X):\n",
    "    return scipy.special.softmax(model(X).logits[-1].detach().numpy())\n",
    "\n",
    "def interaction_value_di(model, X, tokens):\n",
    "    token1, token2 = tokens\n",
    "    AB = get_prediction_softmax(model, X)\n",
    "    \n",
    "    X_t1 = X.clone()\n",
    "    X_t1[token1] = tokenizer.unk_token_id\n",
    "    A = get_prediction_softmax(model, X_t1)\n",
    "    \n",
    "    X_t2 = X.clone()\n",
    "    X_t2[token2] = tokenizer.unk_token_id\n",
    "    B = get_prediction_softmax(model, X_t2)\n",
    "\n",
    "    \n",
    "    X_t12 = X.clone()\n",
    "    X_t12[token2] = tokenizer.unk_token_id\n",
    "    X_t12[token1] = tokenizer.unk_token_id\n",
    "    phi = get_prediction_softmax(model, X_t12)\n",
    "    \n",
    "    val = AB - A - B + phi\n",
    "    val = np.linalg.norm(val)\n",
    "    return val\n",
    "\n",
    "def mwe_distance_interaction(encoded_row, row, col):\n",
    "    iv_mwe = []\n",
    "    # col = 'weak_mwe' | 'strong_mwe'\n",
    "    mwes = row[col]\n",
    "    for mwe in mwes:\n",
    "\n",
    "        for i in range(len(mwe)):\n",
    "            for j in range(len(mwe)):\n",
    "                if i > j:\n",
    "                    if len([x for x in mwe if x >= seq_len]) > 0:\n",
    "                        continue\n",
    "                    iv = interaction_value_di(model, encoded_row, [mwe[i]-1, mwe[j]-1])\n",
    "                    iv_mwe.append([iv, abs((mwe[i]-1-(mwe[j]-1))),mwe])\n",
    "    return iv_mwe\n",
    "weak_mwe_distance = []\n",
    "strong_mwe_distance = []\n",
    "\n",
    "# weak_mwe_distance = Parallel(n_jobs=num_cores)(\n",
    "#     delayed(mwe_distance_interaction)(X[i], row, 'weak_mwe') for i, row in test.iterrows())\n",
    "\n",
    "# strong_mwe_distance = Parallel(n_jobs=num_cores)(\n",
    "#     delayed(mwe_distance_interaction)(X[i], row, 'strong_mwe') for i, row in test.iterrows())\n",
    "\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "    if i%100==0:\n",
    "        print(i, len(test), f'{i*100/len(test)}%')\n",
    "    weak_mwe_distance.extend(mwe_distance_interaction(X[i], row, 'weak_mwe'))\n",
    "    strong_mwe_distance.extend(mwe_distance_interaction(X[i], row, 'strong_mwe'))\n",
    "\n",
    "pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore']).to_pickle('weak_mwe_distance1.pkl')\n",
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore']).to_pickle('strong_mwe_distance1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd809d-0069-4808-96e3-d39aae242337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b85413-4a72-49bd-9108-e0c902b2a49e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.939495Z",
     "iopub.status.idle": "2023-08-24T21:56:38.939811Z",
     "shell.execute_reply": "2023-08-24T21:56:38.939677Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.939664Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Fetching Average Distance...\")\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def calculate_interaction(encoded_row, row):\n",
    "    interactions = []\n",
    "    for j in range( seq_len):\n",
    "        for k in range(j+1, seq_len):\n",
    "\n",
    "            if j+k >= seq_len:\n",
    "                continue\n",
    "            if encoded_row[j] == tokenizer.unk_token_id or encoded_row[k] == tokenizer.unk_token_id:\n",
    "                continue\n",
    "            \n",
    "            iv = interaction_value_di(model, encoded_row, [j, k])\n",
    "            interactions.append([iv, abs(k -j),[j,k]])\n",
    "    return interactions\n",
    "\n",
    "average_distance = []\n",
    "# start_time =  datetime.datetime.now()\n",
    "# for i, row in test.iterrows():\n",
    "#     # if i%9 == 0 or i<=100:\n",
    "#     print(i, len(test), f'{i*100/len(test)}%', (datetime.datetime.now() - start_time).seconds)\n",
    "#     start_time = datetime.datetime.now()\n",
    "#     average_distance.extend(calculate_interaction(X[i], row))\n",
    "\n",
    "num_cores = 9\n",
    "for x in range(0, len(test), 99):\n",
    "    print(x, len(test), f'{100*x/len(test)}%')\n",
    "    average_distance.extend(Parallel(n_jobs=num_cores)(\n",
    "        delayed(calculate_interaction)(X[i], row) for i, row in tqdm(test[x:x+99].iterrows())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79101d8-f90d-40ba-b007-e522fb779c68",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.940943Z",
     "iopub.status.idle": "2023-08-24T21:56:38.941209Z",
     "shell.execute_reply": "2023-08-24T21:56:38.941101Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.941088Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_dist = [item for sublist in average_distance for item in sublist]\n",
    "pd.DataFrame(avg_dist, columns = ['I', 'posdis', 'ignore']).to_pickle('average_distance1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297cd3b-ad2c-4670-912e-565d8ceb34e9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.942268Z",
     "iopub.status.idle": "2023-08-24T21:56:38.942517Z",
     "shell.execute_reply": "2023-08-24T21:56:38.942412Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.942400Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# avg_dist = [item for sublist in average_distance for item in sublist]\n",
    "\n",
    "def plot_mean(avg_path='average_distance.pkl', weak_path='weak_mwe_distance.pkl', strong_path='strong_mwe_distance.pkl'):\n",
    "    avg_dist = pd.read_pickle(avg_path)\n",
    "    avg_df = pd.DataFrame(avg_dist, columns = ['I', 'posdis', 'ignore']).groupby('posdis')['I'].agg( ['mean', 'count', 'std']).rename(columns = {'mean':'avg_mean', 'count':'avg_count', 'std':'avg_std'})\n",
    "    weak_mwe_distance = pd.read_pickle(weak_path)\n",
    "    weak_mwe_df = pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore']).groupby('posdis')['I'].agg( ['mean', 'count', 'std']).rename(columns = {'mean':'weak_mean', 'count':'weak_count', 'std':'weak_std'})\n",
    "    weak_mwe_df = weak_mwe_df.drop(0)\n",
    "    strong_mwe_distance = pd.read_pickle(strong_path)\n",
    "    strong_mwe_df = pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore']).groupby('posdis')['I'].agg( ['mean', 'count', 'std']).rename(columns = {'mean':'strong_mean', 'count':'strong_count', 'std':'strong_std'})\n",
    "    abc = pd.concat([avg_df, weak_mwe_df, strong_mwe_df], axis=1)\n",
    "    display(abc)\n",
    "    abc = abc[abc['weak_count'] >=50]\n",
    "    abc[['avg_mean', 'weak_mean']].plot()\n",
    "    plt.show()\n",
    "plot_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e62896-a71a-43cb-80ff-d91887fa8319",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.943897Z",
     "iopub.status.idle": "2023-08-24T21:56:38.944155Z",
     "shell.execute_reply": "2023-08-24T21:56:38.944046Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.944035Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boxplot_posdis(avg_path='average_distance.pkl', weak_path='weak_mwe_distance.pkl', strong_path='strong_mwe_distance.pkl'):\n",
    "    avg_dist = pd.read_pickle(avg_path)\n",
    "    weak_mwe_distance = pd.read_pickle(weak_path)\n",
    "    strong_mwe_distance = pd.read_pickle(strong_path)\n",
    "    \n",
    "    avg_df = pd.DataFrame(avg_dist, columns = ['I', 'posdis', 'ignore']).drop(columns = ['ignore']).assign(Location='avg')\n",
    "    weak_df = pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore']).drop(columns = ['ignore']).assign(Location='weak')\n",
    "    weak_df = weak_df[weak_df['posdis']!=0].copy()\n",
    "    strong_df = pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore']).drop(columns = ['ignore']).assign(Location='strong')\n",
    "    cdf = pd.concat([avg_df, weak_df])#, strong_df])    \n",
    "    cdf = cdf[cdf['posdis']<=5].copy()\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    ax = sns.boxplot(x=\"posdis\", y='I',hue=\"Location\", data=cdf)     #hue=\"Letter\",\n",
    "    plt.show()\n",
    "\n",
    "boxplot_posdis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef6dcf-f9cc-49c9-aac8-5f3028f00cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7f603-c90c-44aa-abdf-17d1a898a078",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.945688Z",
     "iopub.status.idle": "2023-08-24T21:56:38.946085Z",
     "shell.execute_reply": "2023-08-24T21:56:38.945944Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.945927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# avg_df.boxplot(column = ['I'], by = 'posdis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c53f1-8ec6-4f39-b60b-f528a61b49a6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.947568Z",
     "iopub.status.idle": "2023-08-24T21:56:38.948271Z",
     "shell.execute_reply": "2023-08-24T21:56:38.947796Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.947780Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc9087-e4a3-4587-82bc-e851a4b6b7fa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.949977Z",
     "iopub.status.idle": "2023-08-24T21:56:38.950296Z",
     "shell.execute_reply": "2023-08-24T21:56:38.950172Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.950158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model(X[0:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d853449-b783-4087-8d90-c4c0c413fde0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.951871Z",
     "iopub.status.idle": "2023-08-24T21:56:38.952156Z",
     "shell.execute_reply": "2023-08-24T21:56:38.952043Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.952030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "[x for x in testlist_text if 'Although he wrote' in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95911c8d-5b2c-4b78-a774-0eaaf4a905b0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.953091Z",
     "iopub.status.idle": "2023-08-24T21:56:38.953387Z",
     "shell.execute_reply": "2023-08-24T21:56:38.953265Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.953252Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_mode = 1 # [norm of softmax ]\n",
    "\n",
    "\n",
    "# TODO: Fix the prediction fn. Might have to incorporate\n",
    "#  target variable to get the logit for the target variable instead of max\n",
    "predict_fn = llm_helper.get_prediction_fn(model, pred_mode = pred_mode)\n",
    "\n",
    "\n",
    "\n",
    "torch.no_grad()\n",
    "\n",
    "obj = RegressionGame(X = X[0:k], y=None, function = predict_fn, transform = torch.as_tensor)\n",
    "\n",
    "X_samp = X[k:(N+k)]\n",
    "\n",
    "shapley_values = np.empty((0, X.shape[1]))\n",
    "partial_residuals = np.empty((0, X.shape[1]))\n",
    "games = np.empty((0, 2 ** X.shape[1]))\n",
    "\n",
    "print(\"SHape\")\n",
    "print(X.shape[1])\n",
    "\n",
    "print(\"  ..ok!\")\n",
    "print(\"Generating explanations..\")\n",
    "\n",
    "for i in range(0, N):\n",
    "    example_row = X_samp[i,:].reshape((1,X_samp.shape[1]))\n",
    "    game = obj.getKernelSHAPGame(example_row)\n",
    "    games = np.append(games, game.reshape((1,game.shape[0])), axis = 0)\n",
    "    results, residualGame, origGame = getShapleyProjection(game)\n",
    "    shapley_values = np.append(shapley_values,\n",
    "                               np.array([np.flip(results[-1])]), axis=0)\n",
    "    partial_residuals = np.append(partial_residuals,\n",
    "                                  np.array([np.flip(norm(residualGame, axis = 0)/norm(origGame, axis = 0))]), axis = 0)\n",
    "    print(\"%s/%s samples done.\" % (i+1, N))\n",
    "    \n",
    "\n",
    "    if i % 100 == 0:\n",
    "        pd.DataFrame(X_samp).to_csv('data/llm_input.csv')\n",
    "        pd.DataFrame(shapley_values).to_csv('data/llm_shapley_values.csv')\n",
    "        pd.DataFrame(partial_residuals).to_csv('data/llm_partial_residuals.csv')\n",
    "\n",
    "print(\" Explanations saved to data/llm_*.csv!\")\n",
    "\n",
    "pd.DataFrame(X_samp).to_csv('data/llm_input.csv')\n",
    "pd.DataFrame(shapley_values).to_csv('data/llm_shapley_values.csv')\n",
    "pd.DataFrame(partial_residuals).to_csv('data/llm_partial_residuals.csv')\n",
    "\n",
    "\"\"\"\n",
    "TODO: \n",
    "1. How to get base line features for the text generation process? \n",
    "2. What is the appropriate metric for shapley score. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22e10c-cfff-4263-bc32-f15b5e366605",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.954573Z",
     "iopub.status.idle": "2023-08-24T21:56:38.955099Z",
     "shell.execute_reply": "2023-08-24T21:56:38.954896Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.954871Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "partial_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85b61f-b7d2-4053-b597-712cdac20257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8404e0-d4f3-4fad-b020-58ad8f706e8f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.956792Z",
     "iopub.status.idle": "2023-08-24T21:56:38.957137Z",
     "shell.execute_reply": "2023-08-24T21:56:38.957001Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.956987Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict_fn = llm_helper.get_prediction_fn(model, pred_mode = 1)\n",
    "\n",
    "\n",
    "\n",
    "# torch.no_grad()\n",
    "\n",
    "\n",
    "# # obj = RegressionGame(X = X[0:k], y=y[0:k], function = predict_fn, transform = torch.as_tensor)\n",
    "# obj = RegressionGame(X = X[0:k], y=None, function = predict_fn, transform = torch.as_tensor)\n",
    "\n",
    "# X_samp = X[k:(N+k)]\n",
    "\n",
    "# shapley_values = np.empty((0, X.shape[1]))\n",
    "# partial_residuals = np.empty((0, X.shape[1]))\n",
    "# games = np.empty((0, 2 ** X.shape[1]))\n",
    "\n",
    "# print(\"SHape\")\n",
    "# print(X.shape[1])\n",
    "\n",
    "# print(\"  ..ok!\")\n",
    "# print(\"Generating explanations..\")\n",
    "\n",
    "# for i in range(0, N):\n",
    "#     example_row = X_samp[i,:].reshape((1,X_samp.shape[1]))\n",
    "#     game = obj.getKernelSHAPGame(example_row)\n",
    "#     games = np.append(games, game.reshape((1,game.shape[0])), axis = 0)\n",
    "#     results, residualGame, origGame = getShapleyProjection(game)\n",
    "#     shapley_values = np.append(shapley_values,\n",
    "#                                np.array([np.flip(results[-1])]), axis=0)\n",
    "#     partial_residuals = np.append(partial_residuals,\n",
    "#                                   np.array([np.flip(norm(residualGame, axis = 0)/norm(origGame, axis = 0))]), axis = 0)\n",
    "#     print(\"%s/%s samples done.\" % (i+1, N))\n",
    "\n",
    "# print(\" Explanations saved to data/llm_*.csv!\")\n",
    "\n",
    "# pd.DataFrame(X_samp).to_csv('data/llm_input.csv')\n",
    "# pd.DataFrame(shapley_values).to_csv('data/llm_shapley_values.csv')\n",
    "# pd.DataFrame(partial_residuals).to_csv('data/llm_partial_residuals.csv')\n",
    "\n",
    "# \"\"\"\n",
    "# TODO: \n",
    "# 1. How to get base line features for the text generation process? \n",
    "# 2. What is the appropriate metric for shapley score. \n",
    "# 3. issue here, check why I was not able to make k = 40. model is probably not able to take more than 25. Check\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbff028-32d9-4cbc-94d3-9574243e1d06",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.958822Z",
     "iopub.status.idle": "2023-08-24T21:56:38.959076Z",
     "shell.execute_reply": "2023-08-24T21:56:38.958970Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.958958Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1e48-e0a0-4692-8905-7a8322da0dc9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-24T21:56:38.960210Z",
     "iopub.status.idle": "2023-08-24T21:56:38.960466Z",
     "shell.execute_reply": "2023-08-24T21:56:38.960349Z",
     "shell.execute_reply.started": "2023-08-24T21:56:38.960338Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "partial_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9c1e8-b53f-4f3e-bc3c-4d579f6a6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "                            \n",
    "# s_l[k] = '[MASK]'\n",
    "s_l = \"What is [MASK] name?\"\n",
    "print(s_l)\n",
    "og =  tokenizer(s_l, padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "if cuda:\n",
    "    og = og.cuda()\n",
    "\n",
    "print(og.shape)\n",
    "og = og.reshape(1, -1)\n",
    "mask_token_index = torch.nonzero(og[0] == tokenizer.mask_token_id, as_tuple=False).squeeze(-1)\n",
    "print(mask_token_index)\n",
    "\n",
    "print(og.shape)\n",
    "logits = model(og).logits\n",
    "print(outputs.shape)\n",
    "\n",
    "# print(result)\n",
    "print(logits.shape)\n",
    "print(mask_token_index)\n",
    "print(logits[0, mask_token_index, :].shape)\n",
    "print(logits.argmax(axis=-1)[0, mask_token_index])\n",
    "print('asdasd')\n",
    "abc = logits[0, mask_token_index, :].argmax(axis=-1)\n",
    "print(abc)\n",
    "abc = logits.argmax(axis=-1)\n",
    "print(abc)\n",
    "print(tokenizer.decode(abc[0]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
