{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af294e1d-0794-4a9a-b981-69ad7c9d4001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T20:47:06.286840Z",
     "iopub.status.busy": "2023-08-19T20:47:06.286615Z",
     "iopub.status.idle": "2023-08-19T20:47:07.835680Z",
     "shell.execute_reply": "2023-08-19T20:47:07.834976Z",
     "shell.execute_reply.started": "2023-08-19T20:47:06.286820Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dependencies..\n",
      "Seq Length: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing dependencies..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import scipy\n",
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "from scipy.linalg import norm \n",
    "import pandas as pd\n",
    "import os\n",
    "# from util import RegressionGame\n",
    "# from util_sparse import getShapleyProjection\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "# import shap\n",
    "# import llm_helper\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "if not os.path.exists('__dcache__'):\n",
    "    os.makedirs('__dcache__')\n",
    "\n",
    "# N = 6000\n",
    "# print(\"Explanation count: %s\" % N)\n",
    "# k = 100\n",
    "# print(\"SHAP sample count: %s\" % k)\n",
    "seq_len = 50\n",
    "print(\"Seq Length: %s\" % seq_len)\n",
    "\n",
    "# Setup\n",
    "np.random.seed(1)\n",
    "# model = llm_helper.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da144645-241a-4cde-991e-f73e335410db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3070fd-3798-4285-9cd8-958dd6607407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e483ca-93dc-4903-912c-e9db286c64c2",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77f68b9-de64-46ad-b985-22bf0bd9dec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T20:47:07.837959Z",
     "iopub.status.busy": "2023-08-19T20:47:07.837590Z",
     "iopub.status.idle": "2023-08-19T20:47:12.099448Z",
     "shell.execute_reply": "2023-08-19T20:47:12.098685Z",
     "shell.execute_reply.started": "2023-08-19T20:47:07.837932Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda = True\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "if cuda:\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "else:\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2', use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "test['length'] = test['sentence'].str.split().str.len()\n",
    "# X = tokenizer(test['sentence'].to_list(), padding=True,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d19718-1620-489f-946c-c89321e2b050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T20:47:12.100972Z",
     "iopub.status.busy": "2023-08-19T20:47:12.100335Z",
     "iopub.status.idle": "2023-08-19T20:47:12.125798Z",
     "shell.execute_reply": "2023-08-19T20:47:12.124871Z",
     "shell.execute_reply.started": "2023-08-19T20:47:12.100945Z"
    }
   },
   "outputs": [],
   "source": [
    "# X = X.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774f42b1-6563-4fa4-9594-cece6e86ebeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T20:47:12.127113Z",
     "iopub.status.busy": "2023-08-19T20:47:12.126866Z",
     "iopub.status.idle": "2023-08-19T21:13:28.314743Z",
     "shell.execute_reply": "2023-08-19T21:13:28.313838Z",
     "shell.execute_reply.started": "2023-08-19T20:47:12.127082Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10265it [26:16,  6.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# num_cores = 10\n",
    "\n",
    "def get_prediction_softmax(model, X, token_next):\n",
    "    if cuda:\n",
    "        return torch.softmax(model(X).logits[token_next:], dim=1)\n",
    "    else:\n",
    "        return scipy.special.softmax(model(X).logits[token_next:].detach().numpy(), axis=1)\n",
    "\n",
    "def interaction_value_di(model, X, tokens):\n",
    "    token1, token2 = tokens\n",
    "    \n",
    "    token_next = max(token1, token2) + 1\n",
    "    AB = get_prediction_softmax(model, X, token_next)\n",
    "    \n",
    "    X_t1 = X.clone()\n",
    "    X_t1[token1] = tokenizer.unk_token_id\n",
    "    A = get_prediction_softmax(model, X_t1, token_next)\n",
    "    \n",
    "    X_t2 = X.clone()\n",
    "    X_t2[token2] = tokenizer.unk_token_id\n",
    "    B = get_prediction_softmax(model, X_t2, token_next)\n",
    "\n",
    "    X_t12 = X.clone()\n",
    "    X_t12[token2] = tokenizer.unk_token_id\n",
    "    X_t12[token1] = tokenizer.unk_token_id\n",
    "    phi = get_prediction_softmax(model, X_t12, token_next)\n",
    "    \n",
    "    val = AB - A - B + phi\n",
    "    if cuda:\n",
    "        val = torch.linalg.norm(val, dim=1).cpu()\n",
    "    else:\n",
    "        val = np.linalg.norm(val, axis=1)\n",
    "    \n",
    "    del X_t1, X_t2, X_t12,  AB, A, B, phi\n",
    "    if cuda:\n",
    "        return val.detach(), token_next\n",
    "    else:\n",
    "        return val, token_next\n",
    "\n",
    "def mwe_distance_interaction(encoded_row, row, col, row_number):\n",
    "    iv_mwe = []\n",
    "    # col = 'weak_mwe' | 'strong_mwe'\n",
    "    \n",
    "    mwes = row[col]\n",
    "    for mwe in mwes:\n",
    "\n",
    "        for i in range(len(mwe)):\n",
    "            for j in range(len(mwe)):\n",
    "                if i > j:\n",
    "                    if len([x for x in mwe if x >= seq_len]) > 0:\n",
    "                        continue\n",
    "                    \n",
    "                    iv = interaction_value_di(model, encoded_row, [mwe[i], mwe[j]])\n",
    "                    iv_mwe.append([iv, abs((mwe[i]-mwe[j])),mwe, row_number, i, j])\n",
    "    # print(torch.cuda.memory_allocated()/(1024*1024*1024))\n",
    "    return iv_mwe\n",
    "weak_mwe_distance = []\n",
    "strong_mwe_distance = []\n",
    "\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows()):\n",
    "    # if row_number%100==0:\n",
    "        # print(row_number, len(test), f'{row_number*100/len(test)}%')\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    \n",
    "    # print(\"Start\",torch.cuda.memory_allocated()/(1024*1024*1024))\n",
    "    weak_mwe_distance.extend(mwe_distance_interaction(abc, row, 'weak_mwe', row_number))\n",
    "    strong_mwe_distance.extend(mwe_distance_interaction(abc, row, 'strong_mwe', row_number))\n",
    "    \n",
    "    # print(torch.cuda.memory_allocated()/(1024*1024*1024))\n",
    "    del abc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b60c9-bbb0-4e29-8260-1fa98aeb85f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3e8a36-7551-4e6a-9612-bb19fd8f3b79",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-08-19T21:13:28.316552Z",
     "iopub.status.busy": "2023-08-19T21:13:28.315938Z",
     "iopub.status.idle": "2023-08-19T21:13:28.355373Z",
     "shell.execute_reply": "2023-08-19T21:13:28.354460Z",
     "shell.execute_reply.started": "2023-08-19T21:13:28.316531Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'device': 0,\n",
       "  'address': 42991616000,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 19660800,\n",
       "  'active_size': 19660800,\n",
       "  'requested_size': 19660800,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 3145728,\n",
       "    'requested_size': 3145728,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'requested_size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 1310720, 'requested_size': 1206168, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43012587520,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 1540096,\n",
       "  'active_size': 1540096,\n",
       "  'requested_size': 1534000,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 3072,\n",
       "    'requested_size': 3072,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 1048576, 'requested_size': 1048576, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 9216, 'requested_size': 9216, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 512, 'requested_size': 4, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 12288, 'requested_size': 12288, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 3072, 'requested_size': 3072, 'state': 'active_allocated'},\n",
       "   {'size': 557056, 'requested_size': 296, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43014684672,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 1206168, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43035656192,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 2359296,\n",
       "    'requested_size': 2359296,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 1206168, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43056627712,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2097152,\n",
       "  'active_size': 2097152,\n",
       "  'requested_size': 2097152,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 1048576,\n",
       "    'requested_size': 1048576,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 1048576, 'requested_size': 1048576, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 43058724864,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'requested_size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 1206168, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43079696384,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 1206168, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43100667904,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2097152,\n",
       "  'active_size': 2097152,\n",
       "  'requested_size': 2097152,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 1048576,\n",
       "    'requested_size': 1048576,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 1048576, 'requested_size': 1048576, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 43243274240,\n",
       "  'total_size': 155189248,\n",
       "  'allocated_size': 155189248,\n",
       "  'active_size': 155189248,\n",
       "  'requested_size': 154389504,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 155189248,\n",
       "    'requested_size': 154389504,\n",
       "    'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 43398463488,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 2359296,\n",
       "    'requested_size': 2359296,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 1206168, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43419435008,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'requested_size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 1407196, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43440406528,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43461378048,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 2359296,\n",
       "    'requested_size': 2359296,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43482349568,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2097152,\n",
       "  'active_size': 2097152,\n",
       "  'requested_size': 2097152,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 1048576,\n",
       "    'requested_size': 1048576,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 1048576, 'requested_size': 1048576, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 43484446720,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'requested_size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43505418240,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43526389760,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 2359296,\n",
       "    'requested_size': 2359296,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43547361280,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2097152,\n",
       "  'active_size': 2097152,\n",
       "  'requested_size': 2097152,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 1048576,\n",
       "    'requested_size': 1048576,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 1048576, 'requested_size': 1048576, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 43549458432,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'requested_size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43570429952,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43591401472,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 2359296,\n",
       "    'requested_size': 2359296,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43612372992,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 2097152,\n",
       "  'active_size': 2097152,\n",
       "  'requested_size': 2097152,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 1048576,\n",
       "    'requested_size': 1048576,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 1048576, 'requested_size': 1048576, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 43614470144,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 2359296, 'requested_size': 2359296, 'state': 'active_allocated'},\n",
       "   {'size': 7077888, 'requested_size': 7077888, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43635441664,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 18874368,\n",
       "  'active_size': 18874368,\n",
       "  'requested_size': 18874368,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 2097152, 'requested_size': 0, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43656413184,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 20971520,\n",
       "  'active_size': 20971520,\n",
       "  'requested_size': 20316160,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 2359296,\n",
       "    'requested_size': 2359296,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 9437184, 'requested_size': 9437184, 'state': 'active_allocated'},\n",
       "   {'size': 9175040, 'requested_size': 8519680, 'state': 'active_allocated'}]},\n",
       " {'device': 0,\n",
       "  'address': 43677384704,\n",
       "  'total_size': 2097152,\n",
       "  'allocated_size': 1048576,\n",
       "  'active_size': 1048576,\n",
       "  'requested_size': 1048576,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'small',\n",
       "  'blocks': [{'size': 1048576,\n",
       "    'requested_size': 1048576,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 1048576, 'requested_size': 276480, 'state': 'inactive'}]},\n",
       " {'device': 0,\n",
       "  'address': 43679481856,\n",
       "  'total_size': 20971520,\n",
       "  'allocated_size': 9437184,\n",
       "  'active_size': 9437184,\n",
       "  'requested_size': 9437184,\n",
       "  'stream': 0,\n",
       "  'segment_type': 'large',\n",
       "  'blocks': [{'size': 9437184,\n",
       "    'requested_size': 9437184,\n",
       "    'state': 'active_allocated'},\n",
       "   {'size': 11534336, 'requested_size': 6030840, 'state': 'inactive'}]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.memory_snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870cb30b-ef69-46af-8191-0d166e60f302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T21:13:28.356448Z",
     "iopub.status.busy": "2023-08-19T21:13:28.356233Z",
     "iopub.status.idle": "2023-08-19T21:13:29.717286Z",
     "shell.execute_reply": "2023-08-19T21:13:29.716423Z",
     "shell.execute_reply.started": "2023-08-19T21:13:28.356430Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token']).to_pickle('weak_mwe_distance_3d.pkl')\n",
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token']).to_pickle('strong_mwe_distance_3d.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6478f6ae-f304-4949-95fe-83144894a395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T21:13:29.719923Z",
     "iopub.status.busy": "2023-08-19T21:13:29.719727Z",
     "iopub.status.idle": "2023-08-19T21:13:29.868731Z",
     "shell.execute_reply": "2023-08-19T21:13:29.867943Z",
     "shell.execute_reply.started": "2023-08-19T21:13:29.719907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>posdis</th>\n",
       "      <th>ignore</th>\n",
       "      <th>row_number</th>\n",
       "      <th>first_token</th>\n",
       "      <th>second_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([tensor(0.2753)], 40)</td>\n",
       "      <td>1</td>\n",
       "      <td>[38, 39]</td>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([tensor(0.2149), tensor(0.0847), tensor(0.092...</td>\n",
       "      <td>1</td>\n",
       "      <td>[12, 13]</td>\n",
       "      <td>418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([tensor(0.0558), tensor(0.2328), tensor(0.130...</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 6, 7]</td>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([tensor(0.1867), tensor(0.1216), tensor(0.149...</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 6, 7]</td>\n",
       "      <td>462</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([tensor(0.3418), tensor(0.1314), tensor(0.195...</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 6, 7]</td>\n",
       "      <td>462</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>([tensor(0.6572), tensor(0.2784), tensor(0.260...</td>\n",
       "      <td>1</td>\n",
       "      <td>[11, 12, 13, 14, 15]</td>\n",
       "      <td>10006</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>([tensor(0.3913), tensor(0.0865), tensor(0.028...</td>\n",
       "      <td>4</td>\n",
       "      <td>[11, 12, 13, 14, 15]</td>\n",
       "      <td>10006</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>([tensor(0.3599), tensor(0.1236), tensor(0.045...</td>\n",
       "      <td>3</td>\n",
       "      <td>[11, 12, 13, 14, 15]</td>\n",
       "      <td>10006</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>([tensor(0.3050), tensor(0.2664), tensor(0.046...</td>\n",
       "      <td>2</td>\n",
       "      <td>[11, 12, 13, 14, 15]</td>\n",
       "      <td>10006</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>([tensor(0.4466), tensor(0.2837), tensor(0.061...</td>\n",
       "      <td>1</td>\n",
       "      <td>[11, 12, 13, 14, 15]</td>\n",
       "      <td>10006</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     I  posdis  \\\n",
       "0                               ([tensor(0.2753)], 40)       1   \n",
       "1    ([tensor(0.2149), tensor(0.0847), tensor(0.092...       1   \n",
       "2    ([tensor(0.0558), tensor(0.2328), tensor(0.130...       1   \n",
       "3    ([tensor(0.1867), tensor(0.1216), tensor(0.149...       2   \n",
       "4    ([tensor(0.3418), tensor(0.1314), tensor(0.195...       1   \n",
       "..                                                 ...     ...   \n",
       "324  ([tensor(0.6572), tensor(0.2784), tensor(0.260...       1   \n",
       "325  ([tensor(0.3913), tensor(0.0865), tensor(0.028...       4   \n",
       "326  ([tensor(0.3599), tensor(0.1236), tensor(0.045...       3   \n",
       "327  ([tensor(0.3050), tensor(0.2664), tensor(0.046...       2   \n",
       "328  ([tensor(0.4466), tensor(0.2837), tensor(0.061...       1   \n",
       "\n",
       "                   ignore  row_number  first_token  second_token  \n",
       "0                [38, 39]         373            1             0  \n",
       "1                [12, 13]         418            1             0  \n",
       "2               [5, 6, 7]         462            1             0  \n",
       "3               [5, 6, 7]         462            2             0  \n",
       "4               [5, 6, 7]         462            2             1  \n",
       "..                    ...         ...          ...           ...  \n",
       "324  [11, 12, 13, 14, 15]       10006            3             2  \n",
       "325  [11, 12, 13, 14, 15]       10006            4             0  \n",
       "326  [11, 12, 13, 14, 15]       10006            4             1  \n",
       "327  [11, 12, 13, 14, 15]       10006            4             2  \n",
       "328  [11, 12, 13, 14, 15]       10006            4             3  \n",
       "\n",
       "[329 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore', 'row_number', 'first_token', 'second_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5a5f5-3546-4561-8f80-f4fb24907777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T10:35:10.317009Z",
     "iopub.status.busy": "2023-08-20T10:35:10.316577Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Average Distance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6618it [17:46:48, 10.71s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Fetching Average Distance...\")\n",
    "\n",
    "\n",
    "def calculate_interaction(encoded_row, row, row_number):\n",
    "    interactions = []\n",
    "    encoded_len = len(encoded_row)\n",
    "    for j in range( min(seq_len, encoded_len)):\n",
    "        for k in range(j+1, min(seq_len, encoded_len, j+14)):\n",
    "            if j+k >= encoded_len:\n",
    "                continue\n",
    "            if encoded_row[j] == tokenizer.unk_token_id or encoded_row[k] == tokenizer.unk_token_id:\n",
    "                continue\n",
    "            \n",
    "            iv = interaction_value_di(model, encoded_row, [j, k])\n",
    "            interactions.append([iv, abs(k -j),row_number, [j,k]])\n",
    "    return interactions\n",
    "\n",
    "average_distance = []\n",
    "start_time =  datetime.datetime.now()\n",
    "# min_row = average_distance[-1][2]\n",
    "# print(min_row)\n",
    "\n",
    "for row_number, row in tqdm(test.iterrows()):\n",
    "    # if i%9 == 0 or i<=100:\n",
    "    # print(i, len(test), f'{i*100/len(test)}%', (datetime.datetime.now() - start_time).seconds)\n",
    "    # start_time = datetime.datetime.now()\n",
    "    abc =  tokenizer(row['sentence'], padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    if cuda:\n",
    "        abc = abc.cuda()\n",
    "\n",
    "    \n",
    "    average_distance.extend(calculate_interaction(abc, row, row_number))\n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "# \n",
    "# num_cores = 9\n",
    "# for x in range(0, len(test), 99):\n",
    "#     print(x, len(test), f'{100*x/len(test)}%')\n",
    "#     fabc =  lambda x : tokenizer(x, padding=False,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids[0]\n",
    "    \n",
    "#     average_distance.extend(Parallel(n_jobs=num_cores)(\n",
    "#         delayed(calculate_interaction)(fabc(row['sentence']), row, i) for i, row in tqdm(test[x:x+99].iterrows())))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8e00c-9489-4174-a5e6-b60a287e11ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T10:02:22.296384Z",
     "iopub.status.busy": "2023-08-20T10:02:22.295947Z",
     "iopub.status.idle": "2023-08-20T10:03:01.240585Z",
     "shell.execute_reply": "2023-08-20T10:03:01.239828Z",
     "shell.execute_reply.started": "2023-08-20T10:02:22.296363Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(average_distance, open('average_distance_3d.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6829488-fe87-49e0-b606-a39640d7f393",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-20T10:02:16.853560Z",
     "iopub.status.idle": "2023-08-20T10:02:16.853845Z",
     "shell.execute_reply": "2023-08-20T10:02:16.853709Z",
     "shell.execute_reply.started": "2023-08-20T10:02:16.853697Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(average_distance, columns = ['I', 'posdis', 'row_number', 'word_pair']).to_pickle('average_distance_3d.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91405974-39af-486a-a013-6b2b4c313d57",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b2769-b5ee-46fc-b063-8ff994687038",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.260099Z",
     "iopub.status.idle": "2023-08-19T21:13:35.260341Z",
     "shell.execute_reply": "2023-08-19T21:13:35.260239Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.260225Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "a = np.unique([y[-1]-y[0] for x in test['_'].to_list() for y in x], return_counts=True)\n",
    "print({x:y for x,y in zip(a[0], a[1][::-1].cumsum()[::-1])})\n",
    "print(np.unique([z for x in test['_'].to_list() for y in x for z in y], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbd21c-dcc2-4148-9f5c-a9e78d80e7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbcc8062-e2f8-4fbc-88c9-40a582d4041d",
   "metadata": {},
   "source": [
    "# EXPERIMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7725b98f-ac0e-4530-84ca-33a07ba8e5f8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.261962Z",
     "iopub.status.idle": "2023-08-19T21:13:35.262199Z",
     "shell.execute_reply": "2023-08-19T21:13:35.262097Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.262086Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2', use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "test = pd.read_pickle('../mwe_tagger/fsample.pkl')\n",
    "test['length'] = test['sentence'].str.split().str.len()\n",
    "test = test[test['length'] > seq_len].copy().reset_index(drop=True)\n",
    "X = tokenizer(test['sentence'].to_list(), padding=True,  truncation=True, max_length=seq_len, return_tensors ='pt').input_ids\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b37cae3-20d2-4c17-8ae0-49ab862120ca",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.263058Z",
     "iopub.status.idle": "2023-08-19T21:13:35.263310Z",
     "shell.execute_reply": "2023-08-19T21:13:35.263205Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.263193Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# num_cores = 10\n",
    "\n",
    "def get_prediction_softmax(model, X):\n",
    "    return scipy.special.softmax(model(X).logits[-1].detach().numpy())\n",
    "\n",
    "def interaction_value_di(model, X, tokens):\n",
    "    token1, token2 = tokens\n",
    "    AB = get_prediction_softmax(model, X)\n",
    "    \n",
    "    X_t1 = X.clone()\n",
    "    X_t1[token1] = tokenizer.unk_token_id\n",
    "    A = get_prediction_softmax(model, X_t1)\n",
    "    \n",
    "    X_t2 = X.clone()\n",
    "    X_t2[token2] = tokenizer.unk_token_id\n",
    "    B = get_prediction_softmax(model, X_t2)\n",
    "\n",
    "    \n",
    "    X_t12 = X.clone()\n",
    "    X_t12[token2] = tokenizer.unk_token_id\n",
    "    X_t12[token1] = tokenizer.unk_token_id\n",
    "    phi = get_prediction_softmax(model, X_t12)\n",
    "    \n",
    "    val = AB - A - B + phi\n",
    "    val = np.linalg.norm(val)\n",
    "    return val\n",
    "\n",
    "def mwe_distance_interaction(encoded_row, row, col):\n",
    "    iv_mwe = []\n",
    "    # col = 'weak_mwe' | 'strong_mwe'\n",
    "    mwes = row[col]\n",
    "    for mwe in mwes:\n",
    "\n",
    "        for i in range(len(mwe)):\n",
    "            for j in range(len(mwe)):\n",
    "                if i > j:\n",
    "                    if len([x for x in mwe if x >= seq_len]) > 0:\n",
    "                        continue\n",
    "                    iv = interaction_value_di(model, encoded_row, [mwe[i], mwe[j]])\n",
    "                    iv_mwe.append([iv, abs((mwe[i]-mwe[j])),mwe])\n",
    "    return iv_mwe\n",
    "weak_mwe_distance = []\n",
    "strong_mwe_distance = []\n",
    "\n",
    "# weak_mwe_distance = Parallel(n_jobs=num_cores)(\n",
    "#     delayed(mwe_distance_interaction)(X[i], row, 'weak_mwe') for i, row in test.iterrows())\n",
    "\n",
    "# strong_mwe_distance = Parallel(n_jobs=num_cores)(\n",
    "#     delayed(mwe_distance_interaction)(X[i], row, 'strong_mwe') for i, row in test.iterrows())\n",
    "\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "    if i%100==0:\n",
    "        print(i, len(test), f'{i*100/len(test)}%')\n",
    "    weak_mwe_distance.extend(mwe_distance_interaction(X[i], row, 'weak_mwe'))\n",
    "    strong_mwe_distance.extend(mwe_distance_interaction(X[i], row, 'strong_mwe'))\n",
    "\n",
    "pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore']).to_pickle('weak_mwe_distance1.pkl')\n",
    "pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore']).to_pickle('strong_mwe_distance1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd809d-0069-4808-96e3-d39aae242337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b85413-4a72-49bd-9108-e0c902b2a49e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.265172Z",
     "iopub.status.idle": "2023-08-19T21:13:35.265807Z",
     "shell.execute_reply": "2023-08-19T21:13:35.265646Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.265627Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"Fetching Average Distance...\")\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def calculate_interaction(encoded_row, row):\n",
    "    interactions = []\n",
    "    for j in range( seq_len):\n",
    "        for k in range(j+1, seq_len):\n",
    "\n",
    "            if j+k >= seq_len:\n",
    "                continue\n",
    "            if encoded_row[j] == tokenizer.unk_token_id or encoded_row[k] == tokenizer.unk_token_id:\n",
    "                continue\n",
    "            \n",
    "            iv = interaction_value_di(model, encoded_row, [j, k])\n",
    "            interactions.append([iv, abs(k -j),[j,k]])\n",
    "    return interactions\n",
    "\n",
    "average_distance = []\n",
    "# start_time =  datetime.datetime.now()\n",
    "# for i, row in test.iterrows():\n",
    "#     # if i%9 == 0 or i<=100:\n",
    "#     print(i, len(test), f'{i*100/len(test)}%', (datetime.datetime.now() - start_time).seconds)\n",
    "#     start_time = datetime.datetime.now()\n",
    "#     average_distance.extend(calculate_interaction(X[i], row))\n",
    "\n",
    "num_cores = 9\n",
    "for x in range(0, len(test), 99):\n",
    "    print(x, len(test), f'{100*x/len(test)}%')\n",
    "    average_distance.extend(Parallel(n_jobs=num_cores)(\n",
    "        delayed(calculate_interaction)(X[i], row) for i, row in tqdm(test[x:x+99].iterrows())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79101d8-f90d-40ba-b007-e522fb779c68",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.268228Z",
     "iopub.status.idle": "2023-08-19T21:13:35.268787Z",
     "shell.execute_reply": "2023-08-19T21:13:35.268566Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.268548Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_dist = [item for sublist in average_distance for item in sublist]\n",
    "pd.DataFrame(avg_dist, columns = ['I', 'posdis', 'ignore']).to_pickle('average_distance1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297cd3b-ad2c-4670-912e-565d8ceb34e9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.269956Z",
     "iopub.status.idle": "2023-08-19T21:13:35.270256Z",
     "shell.execute_reply": "2023-08-19T21:13:35.270139Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.270125Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# avg_dist = [item for sublist in average_distance for item in sublist]\n",
    "\n",
    "def plot_mean(avg_path='average_distance.pkl', weak_path='weak_mwe_distance.pkl', strong_path='strong_mwe_distance.pkl'):\n",
    "    avg_dist = pd.read_pickle(avg_path)\n",
    "    avg_df = pd.DataFrame(avg_dist, columns = ['I', 'posdis', 'ignore']).groupby('posdis')['I'].agg( ['mean', 'count', 'std']).rename(columns = {'mean':'avg_mean', 'count':'avg_count', 'std':'avg_std'})\n",
    "    weak_mwe_distance = pd.read_pickle(weak_path)\n",
    "    weak_mwe_df = pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore']).groupby('posdis')['I'].agg( ['mean', 'count', 'std']).rename(columns = {'mean':'weak_mean', 'count':'weak_count', 'std':'weak_std'})\n",
    "    weak_mwe_df = weak_mwe_df.drop(0)\n",
    "    strong_mwe_distance = pd.read_pickle(strong_path)\n",
    "    strong_mwe_df = pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore']).groupby('posdis')['I'].agg( ['mean', 'count', 'std']).rename(columns = {'mean':'strong_mean', 'count':'strong_count', 'std':'strong_std'})\n",
    "    abc = pd.concat([avg_df, weak_mwe_df, strong_mwe_df], axis=1)\n",
    "    display(abc)\n",
    "    abc = abc[abc['weak_count'] >=50]\n",
    "    abc[['avg_mean', 'weak_mean']].plot()\n",
    "    plt.show()\n",
    "plot_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e62896-a71a-43cb-80ff-d91887fa8319",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.272008Z",
     "iopub.status.idle": "2023-08-19T21:13:35.273126Z",
     "shell.execute_reply": "2023-08-19T21:13:35.272917Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.272892Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boxplot_posdis(avg_path='average_distance.pkl', weak_path='weak_mwe_distance.pkl', strong_path='strong_mwe_distance.pkl'):\n",
    "    avg_dist = pd.read_pickle(avg_path)\n",
    "    weak_mwe_distance = pd.read_pickle(weak_path)\n",
    "    strong_mwe_distance = pd.read_pickle(strong_path)\n",
    "    \n",
    "    avg_df = pd.DataFrame(avg_dist, columns = ['I', 'posdis', 'ignore']).drop(columns = ['ignore']).assign(Location='avg')\n",
    "    weak_df = pd.DataFrame(weak_mwe_distance, columns = ['I', 'posdis', 'ignore']).drop(columns = ['ignore']).assign(Location='weak')\n",
    "    weak_df = weak_df[weak_df['posdis']!=0].copy()\n",
    "    strong_df = pd.DataFrame(strong_mwe_distance, columns = ['I', 'posdis', 'ignore']).drop(columns = ['ignore']).assign(Location='strong')\n",
    "    cdf = pd.concat([avg_df, weak_df])#, strong_df])    \n",
    "    cdf = cdf[cdf['posdis']<=5].copy()\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    ax = sns.boxplot(x=\"posdis\", y='I',hue=\"Location\", data=cdf)     #hue=\"Letter\",\n",
    "    plt.show()\n",
    "\n",
    "boxplot_posdis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef6dcf-f9cc-49c9-aac8-5f3028f00cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7f603-c90c-44aa-abdf-17d1a898a078",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.274175Z",
     "iopub.status.idle": "2023-08-19T21:13:35.275022Z",
     "shell.execute_reply": "2023-08-19T21:13:35.274890Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.274868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# avg_df.boxplot(column = ['I'], by = 'posdis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c53f1-8ec6-4f39-b60b-f528a61b49a6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.276045Z",
     "iopub.status.idle": "2023-08-19T21:13:35.276330Z",
     "shell.execute_reply": "2023-08-19T21:13:35.276215Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.276202Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc9087-e4a3-4587-82bc-e851a4b6b7fa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.277640Z",
     "iopub.status.idle": "2023-08-19T21:13:35.277943Z",
     "shell.execute_reply": "2023-08-19T21:13:35.277825Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.277811Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model(X[0:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d853449-b783-4087-8d90-c4c0c413fde0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.279834Z",
     "iopub.status.idle": "2023-08-19T21:13:35.280152Z",
     "shell.execute_reply": "2023-08-19T21:13:35.280027Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.280014Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "[x for x in testlist_text if 'Although he wrote' in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95911c8d-5b2c-4b78-a774-0eaaf4a905b0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.281528Z",
     "iopub.status.idle": "2023-08-19T21:13:35.281945Z",
     "shell.execute_reply": "2023-08-19T21:13:35.281713Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.281700Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_mode = 1 # [norm of softmax ]\n",
    "\n",
    "\n",
    "# TODO: Fix the prediction fn. Might have to incorporate\n",
    "#  target variable to get the logit for the target variable instead of max\n",
    "predict_fn = llm_helper.get_prediction_fn(model, pred_mode = pred_mode)\n",
    "\n",
    "\n",
    "\n",
    "torch.no_grad()\n",
    "\n",
    "obj = RegressionGame(X = X[0:k], y=None, function = predict_fn, transform = torch.as_tensor)\n",
    "\n",
    "X_samp = X[k:(N+k)]\n",
    "\n",
    "shapley_values = np.empty((0, X.shape[1]))\n",
    "partial_residuals = np.empty((0, X.shape[1]))\n",
    "games = np.empty((0, 2 ** X.shape[1]))\n",
    "\n",
    "print(\"SHape\")\n",
    "print(X.shape[1])\n",
    "\n",
    "print(\"  ..ok!\")\n",
    "print(\"Generating explanations..\")\n",
    "\n",
    "for i in range(0, N):\n",
    "    example_row = X_samp[i,:].reshape((1,X_samp.shape[1]))\n",
    "    game = obj.getKernelSHAPGame(example_row)\n",
    "    games = np.append(games, game.reshape((1,game.shape[0])), axis = 0)\n",
    "    results, residualGame, origGame = getShapleyProjection(game)\n",
    "    shapley_values = np.append(shapley_values,\n",
    "                               np.array([np.flip(results[-1])]), axis=0)\n",
    "    partial_residuals = np.append(partial_residuals,\n",
    "                                  np.array([np.flip(norm(residualGame, axis = 0)/norm(origGame, axis = 0))]), axis = 0)\n",
    "    print(\"%s/%s samples done.\" % (i+1, N))\n",
    "    \n",
    "\n",
    "    if i % 100 == 0:\n",
    "        pd.DataFrame(X_samp).to_csv('data/llm_input.csv')\n",
    "        pd.DataFrame(shapley_values).to_csv('data/llm_shapley_values.csv')\n",
    "        pd.DataFrame(partial_residuals).to_csv('data/llm_partial_residuals.csv')\n",
    "\n",
    "print(\" Explanations saved to data/llm_*.csv!\")\n",
    "\n",
    "pd.DataFrame(X_samp).to_csv('data/llm_input.csv')\n",
    "pd.DataFrame(shapley_values).to_csv('data/llm_shapley_values.csv')\n",
    "pd.DataFrame(partial_residuals).to_csv('data/llm_partial_residuals.csv')\n",
    "\n",
    "\"\"\"\n",
    "TODO: \n",
    "1. How to get base line features for the text generation process? \n",
    "2. What is the appropriate metric for shapley score. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22e10c-cfff-4263-bc32-f15b5e366605",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.283326Z",
     "iopub.status.idle": "2023-08-19T21:13:35.283902Z",
     "shell.execute_reply": "2023-08-19T21:13:35.283572Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.283522Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "partial_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85b61f-b7d2-4053-b597-712cdac20257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8404e0-d4f3-4fad-b020-58ad8f706e8f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.285421Z",
     "iopub.status.idle": "2023-08-19T21:13:35.285758Z",
     "shell.execute_reply": "2023-08-19T21:13:35.285616Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.285603Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict_fn = llm_helper.get_prediction_fn(model, pred_mode = 1)\n",
    "\n",
    "\n",
    "\n",
    "# torch.no_grad()\n",
    "\n",
    "\n",
    "# # obj = RegressionGame(X = X[0:k], y=y[0:k], function = predict_fn, transform = torch.as_tensor)\n",
    "# obj = RegressionGame(X = X[0:k], y=None, function = predict_fn, transform = torch.as_tensor)\n",
    "\n",
    "# X_samp = X[k:(N+k)]\n",
    "\n",
    "# shapley_values = np.empty((0, X.shape[1]))\n",
    "# partial_residuals = np.empty((0, X.shape[1]))\n",
    "# games = np.empty((0, 2 ** X.shape[1]))\n",
    "\n",
    "# print(\"SHape\")\n",
    "# print(X.shape[1])\n",
    "\n",
    "# print(\"  ..ok!\")\n",
    "# print(\"Generating explanations..\")\n",
    "\n",
    "# for i in range(0, N):\n",
    "#     example_row = X_samp[i,:].reshape((1,X_samp.shape[1]))\n",
    "#     game = obj.getKernelSHAPGame(example_row)\n",
    "#     games = np.append(games, game.reshape((1,game.shape[0])), axis = 0)\n",
    "#     results, residualGame, origGame = getShapleyProjection(game)\n",
    "#     shapley_values = np.append(shapley_values,\n",
    "#                                np.array([np.flip(results[-1])]), axis=0)\n",
    "#     partial_residuals = np.append(partial_residuals,\n",
    "#                                   np.array([np.flip(norm(residualGame, axis = 0)/norm(origGame, axis = 0))]), axis = 0)\n",
    "#     print(\"%s/%s samples done.\" % (i+1, N))\n",
    "\n",
    "# print(\" Explanations saved to data/llm_*.csv!\")\n",
    "\n",
    "# pd.DataFrame(X_samp).to_csv('data/llm_input.csv')\n",
    "# pd.DataFrame(shapley_values).to_csv('data/llm_shapley_values.csv')\n",
    "# pd.DataFrame(partial_residuals).to_csv('data/llm_partial_residuals.csv')\n",
    "\n",
    "# \"\"\"\n",
    "# TODO: \n",
    "# 1. How to get base line features for the text generation process? \n",
    "# 2. What is the appropriate metric for shapley score. \n",
    "# 3. issue here, check why I was not able to make k = 40. model is probably not able to take more than 25. Check\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbff028-32d9-4cbc-94d3-9574243e1d06",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.286777Z",
     "iopub.status.idle": "2023-08-19T21:13:35.287067Z",
     "shell.execute_reply": "2023-08-19T21:13:35.286953Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.286940Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a1e48-e0a0-4692-8905-7a8322da0dc9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-19T21:13:35.288258Z",
     "iopub.status.idle": "2023-08-19T21:13:35.288543Z",
     "shell.execute_reply": "2023-08-19T21:13:35.288428Z",
     "shell.execute_reply.started": "2023-08-19T21:13:35.288415Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "partial_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9c1e8-b53f-4f3e-bc3c-4d579f6a6f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
