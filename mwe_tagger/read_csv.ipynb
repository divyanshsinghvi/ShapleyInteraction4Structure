{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62a58fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.24.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.11)\n",
      "Requirement already satisfied: jinja2 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/andrejerkelens/miniforge3/envs/shapleyres/lib/python3.11/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!../data_processing/setup_spacy.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac23d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append('../data_processing/')\n",
    "import pandas as pd\n",
    "from parse_dep import *\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import tokenizations\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab39a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_pipeline = get_spacy_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7436fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wiki_text_test_parsed2.pred.mwe', sep='\\t', names=[0,'sentence','d'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3941fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10265, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6192361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/Users/andrejerkelens/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    }
   ],
   "source": [
    "wiki_text = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")['text']\n",
    "wiki_text = [w for w in wiki_text if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9de4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d'] = df.apply(lambda x: literal_eval(x['d']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "048927fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.json_normalize(df.d)],axis=1)\n",
    "df = df.drop(columns=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f28ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['toks'].apply(lambda x: [y[0] for y in x])\n",
    "df['sentence'] = df['sentence'].apply(lambda x: literal_eval(x).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68be41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'= Robert_Boulter ='"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164968e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10265, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1883d843",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Note:\n",
    "\n",
    "Only piece is to remove underscore from sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7abb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3285f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentences_mwe(dataset, pipeline = \"spacy\"):\n",
    "    lines = []\n",
    "    for d in dataset:\n",
    "        if pipeline == \"spacy\":\n",
    "            doc = nlp(d)\n",
    "        elif pipeline == \"bpe\":\n",
    "            doc = bpe_pipeline(d)\n",
    "        if doc:\n",
    "            for sent in doc.sents:\n",
    "                lines.append(f\"{word}\\t{word.pos_}\\n\")\n",
    "                lines.append(\"\\n\")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee977f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, two2one = tokenizations.get_alignments(df.iloc[1].tokens, list(map(str, list(bpe_pipeline(wiki_text[1]).sents)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50577ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sent'] = df['sentence'].apply(lambda x: x.replace(\"_\", \" \").replace(\"~\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1b3097d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10265, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f5af589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bpe_tokens'] = df.apply(lambda x: list(map(str, list(bpe_pipeline(x[\"sent\"])))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b386d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_map'] = df.apply(lambda x: tokenizations.get_alignments(x['tokens'], \n",
    "                                                                  x['bpe_tokens'])[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caf92f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [[0], [1], [2], [2], [2], [3]]\n",
       "1        [[0], [1], [1], [1], [2], [3], [4], [5], [6], ...\n",
       "2        [[0], [1], [2], [3], [4], [4], [4], [5], [6], ...\n",
       "3        [[0], [1], [2], [3], [4], [5], [6], [7], [8], ...\n",
       "4        [[0], [1], [2], [3], [4], [5], [6], [7], [8], ...\n",
       "                               ...                        \n",
       "10260    [[0], [1], [2], [3], [4], [5], [6], [7], [7], ...\n",
       "10261    [[0], [0], [1], [2], [3], [4], [5], [6], [7], ...\n",
       "10262    [[0], [0], [0], [1], [2], [3], [4], [5], [5], ...\n",
       "10263    [[0], [1], [2], [2], [3], [4], [5], [6], [7], ...\n",
       "10264    [[0], [1], [2], [3], [4], [5], [6], [7], [8], ...\n",
       "Name: token_map, Length: 10265, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "294e45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_index_dict(input_list):\n",
    "    index_dict = {}\n",
    "    \n",
    "    for index, sublist in enumerate(input_list):\n",
    "        for item in sublist:\n",
    "            if item in index_dict:\n",
    "                index_dict[item].append(index)\n",
    "            else:\n",
    "                index_dict[item] = [index]\n",
    "    \n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a8df529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_map_dict'] = df['token_map'].apply(lambda x: list_to_index_dict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea589232",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>tags</th>\n",
       "      <th>_</th>\n",
       "      <th>~</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bpe_tokens</th>\n",
       "      <th>token_map</th>\n",
       "      <th>token_map_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= Robert Boulter =</td>\n",
       "      <td>[O, B-GROUP, Ī, O]</td>\n",
       "      <td>[[2, 3]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[=, Robert, Boulter, =]</td>\n",
       "      <td>[=, ĠRobert, ĠB, oul, ter, Ġ=]</td>\n",
       "      <td>[[0], [1], [2], [2], [2], [3]]</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2, 3, 4], 3: [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert Boulter is an English film , television...</td>\n",
       "      <td>[B-PERSON, Ī, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[[1, 2]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Robert, Boulter, is, an, English, film, ,, te...</td>\n",
       "      <td>[Robert, ĠB, oul, ter, Ġis, Ġan, ĠEnglish, Ġfi...</td>\n",
       "      <td>[[0], [1], [1], [1], [2], [3], [4], [5], [6], ...</td>\n",
       "      <td>{0: [0], 1: [1, 2, 3], 2: [4], 3: [5], 4: [6],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had a guest @-@ starring role on the televi...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B, Ī, O, O, O, O, O]</td>\n",
       "      <td>[[10, 11]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[He, had, a, guest, @-@, starring, role, on, t...</td>\n",
       "      <td>[He, Ġhad, Ġa, Ġguest, Ġ@, -, @, Ġstarring, Ġr...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [4], [4], [5], [6], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4, 5, 6],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This was followed by a starring role in the pl...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-GROU...</td>\n",
       "      <td>[[14, 15], [24, 25]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[This, was, followed, by, a, starring, role, i...</td>\n",
       "      <td>[This, Ġwas, Ġfollowed, Ġby, Ġa, Ġstarring, Ġr...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [5], [6], [7], [8], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He had a guest role in the television series J...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-COMMUNICATION, Ī, O, B...</td>\n",
       "      <td>[[8, 9], [11, 12]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[He, had, a, guest, role, in, the, television,...</td>\n",
       "      <td>[He, Ġhad, Ġa, Ġguest, Ġrole, Ġin, Ġthe, Ġtele...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [5], [6], [7], [8], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10260</th>\n",
       "      <td>Perhaps the greatest beneficiary of the film '...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Perhaps, the, greatest, beneficiary, of, the,...</td>\n",
       "      <td>[Perhaps, Ġthe, Ġgreatest, Ġbeneficiary, Ġof, ...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [5], [6], [7], [7], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10261</th>\n",
       "      <td>Mosconi claimed in an interview at the time of...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[18, 19], [21, 22, 23], [27, 28], [33, 34, 35]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Mosconi, claimed, in, an, interview, at, the,...</td>\n",
       "      <td>[Mos, coni, Ġclaimed, Ġin, Ġan, Ġinterview, Ġa...</td>\n",
       "      <td>[[0], [0], [1], [2], [3], [4], [5], [6], [7], ...</td>\n",
       "      <td>{0: [0, 1], 1: [2], 2: [3], 3: [4], 4: [5], 5:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10262</th>\n",
       "      <td>Wanderone immediately adopted the Minnesota Fa...</td>\n",
       "      <td>[O, O, O, O, B-FOOD, Ī, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[[5, 6], [18, 19]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Wanderone, immediately, adopted, the, Minneso...</td>\n",
       "      <td>[W, ander, one, Ġimmediately, Ġadopted, Ġthe, ...</td>\n",
       "      <td>[[0], [0], [0], [1], [2], [3], [4], [5], [5], ...</td>\n",
       "      <td>{0: [0, 1, 2], 1: [3], 2: [4], 3: [5], 4: [6],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10263</th>\n",
       "      <td>Author Walter Tevis denied for the rest of his...</td>\n",
       "      <td>[O, B-GROUP, Ī, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[2, 3]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Author, Walter, Tevis, denied, for, the, rest...</td>\n",
       "      <td>[Author, ĠWalter, ĠTe, vis, Ġdenied, Ġfor, Ġth...</td>\n",
       "      <td>[[0], [1], [2], [2], [3], [4], [5], [6], [7], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2, 3], 3: [4], 4: [5], 5:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>Other players would claim , with greater or le...</td>\n",
       "      <td>[O, O-GROUP, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[30, 31]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Other, players, would, claim, ,, with, greate...</td>\n",
       "      <td>[Other, Ġplayers, Ġwould, Ġclaim, Ġ,, Ġwith, Ġ...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [5], [6], [7], [8], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10265 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sent  \\\n",
       "0                                     = Robert Boulter =   \n",
       "1      Robert Boulter is an English film , television...   \n",
       "2      He had a guest @-@ starring role on the televi...   \n",
       "3      This was followed by a starring role in the pl...   \n",
       "4      He had a guest role in the television series J...   \n",
       "...                                                  ...   \n",
       "10260  Perhaps the greatest beneficiary of the film '...   \n",
       "10261  Mosconi claimed in an interview at the time of...   \n",
       "10262  Wanderone immediately adopted the Minnesota Fa...   \n",
       "10263  Author Walter Tevis denied for the rest of his...   \n",
       "10264  Other players would claim , with greater or le...   \n",
       "\n",
       "                                                    tags  \\\n",
       "0                                     [O, B-GROUP, Ī, O]   \n",
       "1            [B-PERSON, Ī, O, O, O, O, O, O, O, O, O, O]   \n",
       "2       [O, O, O, O, O, O, O, O, O, B, Ī, O, O, O, O, O]   \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, B-GROU...   \n",
       "4      [O, O, O, O, O, O, O, B-COMMUNICATION, Ī, O, B...   \n",
       "...                                                  ...   \n",
       "10260  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "10261  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "10262  [O, O, O, O, B-FOOD, Ī, O, O, O, O, O, O, O, O...   \n",
       "10263  [O, B-GROUP, Ī, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "10264  [O, O-GROUP, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                                      _   ~  \\\n",
       "0                                              [[2, 3]]  []   \n",
       "1                                              [[1, 2]]  []   \n",
       "2                                            [[10, 11]]  []   \n",
       "3                                  [[14, 15], [24, 25]]  []   \n",
       "4                                    [[8, 9], [11, 12]]  []   \n",
       "...                                                 ...  ..   \n",
       "10260                                                []  []   \n",
       "10261  [[18, 19], [21, 22, 23], [27, 28], [33, 34, 35]]  []   \n",
       "10262                                [[5, 6], [18, 19]]  []   \n",
       "10263                                          [[2, 3]]  []   \n",
       "10264                                        [[30, 31]]  []   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0                                [=, Robert, Boulter, =]   \n",
       "1      [Robert, Boulter, is, an, English, film, ,, te...   \n",
       "2      [He, had, a, guest, @-@, starring, role, on, t...   \n",
       "3      [This, was, followed, by, a, starring, role, i...   \n",
       "4      [He, had, a, guest, role, in, the, television,...   \n",
       "...                                                  ...   \n",
       "10260  [Perhaps, the, greatest, beneficiary, of, the,...   \n",
       "10261  [Mosconi, claimed, in, an, interview, at, the,...   \n",
       "10262  [Wanderone, immediately, adopted, the, Minneso...   \n",
       "10263  [Author, Walter, Tevis, denied, for, the, rest...   \n",
       "10264  [Other, players, would, claim, ,, with, greate...   \n",
       "\n",
       "                                              bpe_tokens  \\\n",
       "0                         [=, ĠRobert, ĠB, oul, ter, Ġ=]   \n",
       "1      [Robert, ĠB, oul, ter, Ġis, Ġan, ĠEnglish, Ġfi...   \n",
       "2      [He, Ġhad, Ġa, Ġguest, Ġ@, -, @, Ġstarring, Ġr...   \n",
       "3      [This, Ġwas, Ġfollowed, Ġby, Ġa, Ġstarring, Ġr...   \n",
       "4      [He, Ġhad, Ġa, Ġguest, Ġrole, Ġin, Ġthe, Ġtele...   \n",
       "...                                                  ...   \n",
       "10260  [Perhaps, Ġthe, Ġgreatest, Ġbeneficiary, Ġof, ...   \n",
       "10261  [Mos, coni, Ġclaimed, Ġin, Ġan, Ġinterview, Ġa...   \n",
       "10262  [W, ander, one, Ġimmediately, Ġadopted, Ġthe, ...   \n",
       "10263  [Author, ĠWalter, ĠTe, vis, Ġdenied, Ġfor, Ġth...   \n",
       "10264  [Other, Ġplayers, Ġwould, Ġclaim, Ġ,, Ġwith, Ġ...   \n",
       "\n",
       "                                               token_map  \\\n",
       "0                         [[0], [1], [2], [2], [2], [3]]   \n",
       "1      [[0], [1], [1], [1], [2], [3], [4], [5], [6], ...   \n",
       "2      [[0], [1], [2], [3], [4], [4], [4], [5], [6], ...   \n",
       "3      [[0], [1], [2], [3], [4], [5], [6], [7], [8], ...   \n",
       "4      [[0], [1], [2], [3], [4], [5], [6], [7], [8], ...   \n",
       "...                                                  ...   \n",
       "10260  [[0], [1], [2], [3], [4], [5], [6], [7], [7], ...   \n",
       "10261  [[0], [0], [1], [2], [3], [4], [5], [6], [7], ...   \n",
       "10262  [[0], [0], [0], [1], [2], [3], [4], [5], [5], ...   \n",
       "10263  [[0], [1], [2], [2], [3], [4], [5], [6], [7], ...   \n",
       "10264  [[0], [1], [2], [3], [4], [5], [6], [7], [8], ...   \n",
       "\n",
       "                                          token_map_dict  \n",
       "0                 {0: [0], 1: [1], 2: [2, 3, 4], 3: [5]}  \n",
       "1      {0: [0], 1: [1, 2, 3], 2: [4], 3: [5], 4: [6],...  \n",
       "2      {0: [0], 1: [1], 2: [2], 3: [3], 4: [4, 5, 6],...  \n",
       "3      {0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...  \n",
       "4      {0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...  \n",
       "...                                                  ...  \n",
       "10260  {0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...  \n",
       "10261  {0: [0, 1], 1: [2], 2: [3], 3: [4], 4: [5], 5:...  \n",
       "10262  {0: [0, 1, 2], 1: [3], 2: [4], 3: [5], 4: [6],...  \n",
       "10263  {0: [0], 1: [1], 2: [2, 3], 3: [4], 4: [5], 5:...  \n",
       "10264  {0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...  \n",
       "\n",
       "[10265 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sent','tags', '_', '~', 'tokens','bpe_tokens', 'token_map', 'token_map_dict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1d82f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_weak_mwes_together(x):\n",
    "    \n",
    "    mapped_mwes = []\n",
    "    for j, mwe in enumerate(x['_']):\n",
    "        mapped_mwes.append([])\n",
    "        for index in mwe:\n",
    "            \n",
    "            if index-1 in x['token_map_dict']:\n",
    "                for val in x['token_map_dict'][index-1]:\n",
    "                    mapped_mwes[j].append(val+1)\n",
    "                \n",
    "                \n",
    "    return mapped_mwes\n",
    "                   \n",
    "    \n",
    "def map_strong_mwes_together(x):\n",
    "    \n",
    "    mapped_mwes = []\n",
    "    for j, mwe in enumerate(x['~']):\n",
    "        mapped_mwes.append([])\n",
    "        for index in mwe:\n",
    "            \n",
    "            if index-1 in x['token_map_dict']:\n",
    "                for val in x['token_map_dict'][index-1]:\n",
    "                    mapped_mwes[j].append(val+1)\n",
    "                \n",
    "                \n",
    "    return mapped_mwes\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28613400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weak_mwe'] = df.apply(lambda x: map_weak_mwes_together(x),axis=1)\n",
    "df['strong_mwe'] = df.apply(lambda x: map_strong_mwes_together(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a2a460be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>tags</th>\n",
       "      <th>_</th>\n",
       "      <th>weak_mwe</th>\n",
       "      <th>~</th>\n",
       "      <th>strong_mwe</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bpe_tokens</th>\n",
       "      <th>token_map</th>\n",
       "      <th>token_map_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= Robert Boulter =</td>\n",
       "      <td>[O, B-GROUP, Ī, O]</td>\n",
       "      <td>[[2, 3]]</td>\n",
       "      <td>[[2, 3, 4, 5]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[=, Robert, Boulter, =]</td>\n",
       "      <td>[=, ĠRobert, ĠB, oul, ter, Ġ=]</td>\n",
       "      <td>[[0], [1], [2], [2], [2], [3]]</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2, 3, 4], 3: [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert Boulter is an English film , television...</td>\n",
       "      <td>[B-PERSON, Ī, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[[1, 2]]</td>\n",
       "      <td>[[1, 2, 3, 4]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Robert, Boulter, is, an, English, film, ,, te...</td>\n",
       "      <td>[Robert, ĠB, oul, ter, Ġis, Ġan, ĠEnglish, Ġfi...</td>\n",
       "      <td>[[0], [1], [1], [1], [2], [3], [4], [5], [6], ...</td>\n",
       "      <td>{0: [0], 1: [1, 2, 3], 2: [4], 3: [5], 4: [6],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had a guest @-@ starring role on the televi...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B, Ī, O, O, O, O, O]</td>\n",
       "      <td>[[10, 11]]</td>\n",
       "      <td>[[12, 13]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[He, had, a, guest, @-@, starring, role, on, t...</td>\n",
       "      <td>[He, Ġhad, Ġa, Ġguest, Ġ@, -, @, Ġstarring, Ġr...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [4], [4], [5], [6], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4, 5, 6],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This was followed by a starring role in the pl...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-GROU...</td>\n",
       "      <td>[[14, 15], [24, 25]]</td>\n",
       "      <td>[[15, 16], [25, 26]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[This, was, followed, by, a, starring, role, i...</td>\n",
       "      <td>[This, Ġwas, Ġfollowed, Ġby, Ġa, Ġstarring, Ġr...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [5], [6], [7], [8], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He had a guest role in the television series J...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-COMMUNICATION, Ī, O, B...</td>\n",
       "      <td>[[8, 9], [11, 12]]</td>\n",
       "      <td>[[8, 9], [11, 12, 13]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[He, had, a, guest, role, in, the, television,...</td>\n",
       "      <td>[He, Ġhad, Ġa, Ġguest, Ġrole, Ġin, Ġthe, Ġtele...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [5], [6], [7], [8], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10260</th>\n",
       "      <td>Perhaps the greatest beneficiary of the film '...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Perhaps, the, greatest, beneficiary, of, the,...</td>\n",
       "      <td>[Perhaps, Ġthe, Ġgreatest, Ġbeneficiary, Ġof, ...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [5], [6], [7], [7], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10261</th>\n",
       "      <td>Mosconi claimed in an interview at the time of...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[18, 19], [21, 22, 23], [27, 28], [33, 34, 35]]</td>\n",
       "      <td>[[20, 21, 22], [24, 25, 26, 27], [31, 32], [37...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Mosconi, claimed, in, an, interview, at, the,...</td>\n",
       "      <td>[Mos, coni, Ġclaimed, Ġin, Ġan, Ġinterview, Ġa...</td>\n",
       "      <td>[[0], [0], [1], [2], [3], [4], [5], [6], [7], ...</td>\n",
       "      <td>{0: [0, 1], 1: [2], 2: [3], 3: [4], 4: [5], 5:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10262</th>\n",
       "      <td>Wanderone immediately adopted the Minnesota Fa...</td>\n",
       "      <td>[O, O, O, O, B-FOOD, Ī, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[[5, 6], [18, 19]]</td>\n",
       "      <td>[[7, 8, 9], [23, 24]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Wanderone, immediately, adopted, the, Minneso...</td>\n",
       "      <td>[W, ander, one, Ġimmediately, Ġadopted, Ġthe, ...</td>\n",
       "      <td>[[0], [0], [0], [1], [2], [3], [4], [5], [5], ...</td>\n",
       "      <td>{0: [0, 1, 2], 1: [3], 2: [4], 3: [5], 4: [6],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10263</th>\n",
       "      <td>Author Walter Tevis denied for the rest of his...</td>\n",
       "      <td>[O, B-GROUP, Ī, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[2, 3]]</td>\n",
       "      <td>[[2, 3, 4]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Author, Walter, Tevis, denied, for, the, rest...</td>\n",
       "      <td>[Author, ĠWalter, ĠTe, vis, Ġdenied, Ġfor, Ġth...</td>\n",
       "      <td>[[0], [1], [2], [2], [3], [4], [5], [6], [7], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2, 3], 3: [4], 4: [5], 5:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>Other players would claim , with greater or le...</td>\n",
       "      <td>[O, O-GROUP, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[[30, 31]]</td>\n",
       "      <td>[[30, 31]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Other, players, would, claim, ,, with, greate...</td>\n",
       "      <td>[Other, Ġplayers, Ġwould, Ġclaim, Ġ,, Ġwith, Ġ...</td>\n",
       "      <td>[[0], [1], [2], [3], [4], [5], [6], [7], [8], ...</td>\n",
       "      <td>{0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10265 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sent  \\\n",
       "0                                     = Robert Boulter =   \n",
       "1      Robert Boulter is an English film , television...   \n",
       "2      He had a guest @-@ starring role on the televi...   \n",
       "3      This was followed by a starring role in the pl...   \n",
       "4      He had a guest role in the television series J...   \n",
       "...                                                  ...   \n",
       "10260  Perhaps the greatest beneficiary of the film '...   \n",
       "10261  Mosconi claimed in an interview at the time of...   \n",
       "10262  Wanderone immediately adopted the Minnesota Fa...   \n",
       "10263  Author Walter Tevis denied for the rest of his...   \n",
       "10264  Other players would claim , with greater or le...   \n",
       "\n",
       "                                                    tags  \\\n",
       "0                                     [O, B-GROUP, Ī, O]   \n",
       "1            [B-PERSON, Ī, O, O, O, O, O, O, O, O, O, O]   \n",
       "2       [O, O, O, O, O, O, O, O, O, B, Ī, O, O, O, O, O]   \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, B-GROU...   \n",
       "4      [O, O, O, O, O, O, O, B-COMMUNICATION, Ī, O, B...   \n",
       "...                                                  ...   \n",
       "10260  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "10261  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "10262  [O, O, O, O, B-FOOD, Ī, O, O, O, O, O, O, O, O...   \n",
       "10263  [O, B-GROUP, Ī, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "10264  [O, O-GROUP, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                                      _  \\\n",
       "0                                              [[2, 3]]   \n",
       "1                                              [[1, 2]]   \n",
       "2                                            [[10, 11]]   \n",
       "3                                  [[14, 15], [24, 25]]   \n",
       "4                                    [[8, 9], [11, 12]]   \n",
       "...                                                 ...   \n",
       "10260                                                []   \n",
       "10261  [[18, 19], [21, 22, 23], [27, 28], [33, 34, 35]]   \n",
       "10262                                [[5, 6], [18, 19]]   \n",
       "10263                                          [[2, 3]]   \n",
       "10264                                        [[30, 31]]   \n",
       "\n",
       "                                                weak_mwe   ~ strong_mwe  \\\n",
       "0                                         [[2, 3, 4, 5]]  []         []   \n",
       "1                                         [[1, 2, 3, 4]]  []         []   \n",
       "2                                             [[12, 13]]  []         []   \n",
       "3                                   [[15, 16], [25, 26]]  []         []   \n",
       "4                                 [[8, 9], [11, 12, 13]]  []         []   \n",
       "...                                                  ...  ..        ...   \n",
       "10260                                                 []  []         []   \n",
       "10261  [[20, 21, 22], [24, 25, 26, 27], [31, 32], [37...  []         []   \n",
       "10262                              [[7, 8, 9], [23, 24]]  []         []   \n",
       "10263                                        [[2, 3, 4]]  []         []   \n",
       "10264                                         [[30, 31]]  []         []   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0                                [=, Robert, Boulter, =]   \n",
       "1      [Robert, Boulter, is, an, English, film, ,, te...   \n",
       "2      [He, had, a, guest, @-@, starring, role, on, t...   \n",
       "3      [This, was, followed, by, a, starring, role, i...   \n",
       "4      [He, had, a, guest, role, in, the, television,...   \n",
       "...                                                  ...   \n",
       "10260  [Perhaps, the, greatest, beneficiary, of, the,...   \n",
       "10261  [Mosconi, claimed, in, an, interview, at, the,...   \n",
       "10262  [Wanderone, immediately, adopted, the, Minneso...   \n",
       "10263  [Author, Walter, Tevis, denied, for, the, rest...   \n",
       "10264  [Other, players, would, claim, ,, with, greate...   \n",
       "\n",
       "                                              bpe_tokens  \\\n",
       "0                         [=, ĠRobert, ĠB, oul, ter, Ġ=]   \n",
       "1      [Robert, ĠB, oul, ter, Ġis, Ġan, ĠEnglish, Ġfi...   \n",
       "2      [He, Ġhad, Ġa, Ġguest, Ġ@, -, @, Ġstarring, Ġr...   \n",
       "3      [This, Ġwas, Ġfollowed, Ġby, Ġa, Ġstarring, Ġr...   \n",
       "4      [He, Ġhad, Ġa, Ġguest, Ġrole, Ġin, Ġthe, Ġtele...   \n",
       "...                                                  ...   \n",
       "10260  [Perhaps, Ġthe, Ġgreatest, Ġbeneficiary, Ġof, ...   \n",
       "10261  [Mos, coni, Ġclaimed, Ġin, Ġan, Ġinterview, Ġa...   \n",
       "10262  [W, ander, one, Ġimmediately, Ġadopted, Ġthe, ...   \n",
       "10263  [Author, ĠWalter, ĠTe, vis, Ġdenied, Ġfor, Ġth...   \n",
       "10264  [Other, Ġplayers, Ġwould, Ġclaim, Ġ,, Ġwith, Ġ...   \n",
       "\n",
       "                                               token_map  \\\n",
       "0                         [[0], [1], [2], [2], [2], [3]]   \n",
       "1      [[0], [1], [1], [1], [2], [3], [4], [5], [6], ...   \n",
       "2      [[0], [1], [2], [3], [4], [4], [4], [5], [6], ...   \n",
       "3      [[0], [1], [2], [3], [4], [5], [6], [7], [8], ...   \n",
       "4      [[0], [1], [2], [3], [4], [5], [6], [7], [8], ...   \n",
       "...                                                  ...   \n",
       "10260  [[0], [1], [2], [3], [4], [5], [6], [7], [7], ...   \n",
       "10261  [[0], [0], [1], [2], [3], [4], [5], [6], [7], ...   \n",
       "10262  [[0], [0], [0], [1], [2], [3], [4], [5], [5], ...   \n",
       "10263  [[0], [1], [2], [2], [3], [4], [5], [6], [7], ...   \n",
       "10264  [[0], [1], [2], [3], [4], [5], [6], [7], [8], ...   \n",
       "\n",
       "                                          token_map_dict  \n",
       "0                 {0: [0], 1: [1], 2: [2, 3, 4], 3: [5]}  \n",
       "1      {0: [0], 1: [1, 2, 3], 2: [4], 3: [5], 4: [6],...  \n",
       "2      {0: [0], 1: [1], 2: [2], 3: [3], 4: [4, 5, 6],...  \n",
       "3      {0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...  \n",
       "4      {0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...  \n",
       "...                                                  ...  \n",
       "10260  {0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...  \n",
       "10261  {0: [0, 1], 1: [2], 2: [3], 3: [4], 4: [5], 5:...  \n",
       "10262  {0: [0, 1, 2], 1: [3], 2: [4], 3: [5], 4: [6],...  \n",
       "10263  {0: [0], 1: [1], 2: [2, 3], 3: [4], 4: [5], 5:...  \n",
       "10264  {0: [0], 1: [1], 2: [2], 3: [3], 4: [4], 5: [5...  \n",
       "\n",
       "[10265 rows x 10 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sent','tags', '_', 'weak_mwe', '~', 'strong_mwe', 'tokens','bpe_tokens', 'token_map', 'token_map_dict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68df839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "LICENSE                             read_csv.ipynb\r\n",
      "README.md                           \u001b[31mrun_sr_pipeline.sh\u001b[m\u001b[m\r\n",
      "environment.yaml                    sample\r\n",
      "fsample                             sample.csv\r\n",
      "fsample.csv                         \u001b[1m\u001b[36msrc\u001b[m\u001b[m\r\n",
      "fsample.pred.mwe                    sst.model.pickle\r\n",
      "fsample.pred.sst                    \u001b[31msst.sh\u001b[m\u001b[m\r\n",
      "fsample.pred.tags                   \u001b[1m\u001b[36mtagsets\u001b[m\u001b[m\r\n",
      "\u001b[31minstall.sh\u001b[m\u001b[m                          testing.csv\r\n",
      "\u001b[1m\u001b[36mlex\u001b[m\u001b[m                                 \u001b[31mtrain_test_mwe.sh\u001b[m\u001b[m\r\n",
      "make_csv.py                         wiki_text_test_parsed\r\n",
      "\u001b[31mmwe_identify.sh\u001b[m\u001b[m                     wiki_text_test_parsed2\r\n",
      "\u001b[31mmwe_identify_only.sh\u001b[m\u001b[m                wiki_text_test_parsed2.pred.mwe\r\n",
      "\u001b[1m\u001b[36mmwelex\u001b[m\u001b[m                              wiki_text_test_parsed2.pred.tags\r\n",
      "\u001b[31mpostprocess.sh\u001b[m\u001b[m                      wiki_text_test_parsed_PY2.pred.tags\r\n",
      "\u001b[31mpredict_sst.sh\u001b[m\u001b[m                      wiki_text_test_parsed_PY3.pred.tags\r\n",
      "\u001b[31mpreprocess.sh\u001b[m\u001b[m                       wiki_text_test_parsed_all.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4bd209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapleyres",
   "language": "python",
   "name": "shapleyres"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
