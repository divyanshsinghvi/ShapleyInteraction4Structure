{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d49e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a003b300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset turkish-wiki_ner (/home/dsinghvi/.cache/huggingface/datasets/turkish-nlp-suite___turkish-wiki_ner/turkish-WikiNER/1.0.0/8653bd2312d132b985c0abb10bfb847934dfeab8e34ad48ee4502c9d2d455e0f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e878718c11443f87cb6dacf463dbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"turkish-nlp-suite/turkish-wikiNER\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1929e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c07e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = experiment_runner.ExperimentRunner(cuda=True, seq_len=50, model_name = 'xlm-roberta-base', method=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "929361c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset turkish-wiki_ner (/home/dsinghvi/.cache/huggingface/datasets/turkish-nlp-suite___turkish-wiki_ner/turkish-WikiNER/1.0.0/8653bd2312d132b985c0abb10bfb847934dfeab8e34ad48ee4502c9d2d455e0f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ed6ba184324c4c90e77a19edbbf6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "self.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf17e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "self.prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca898bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xlm-roberta-base'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce20dc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d183561bafe64edead1f629664f67586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46525/1475431367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrow_number\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'avg_{self.MODEL_NAME}{suffix}.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "# def get_prediction_softmax(self, X, token_next):\n",
    "#     logits = self.model(X).logits\n",
    "#     if self.SOFTMAX:\n",
    "#         abc =  logits[0, token_next:, :].softmax(dim=-1)\n",
    "#     else:\n",
    "#         abc =  logits[0, token_next:, :]\n",
    "\n",
    "#     if not self.CUDA:\n",
    "#         return abc.detach().numpy()\n",
    "#     else:\n",
    "#         return abc\n",
    "    \n",
    "# def interaction_value_di(self, X, tokens):\n",
    "#     token1, token2 = tokens\n",
    "    \n",
    "#     if self.MODEL_NAME == 'xlm-roberta-base':\n",
    "#         token_next = 0\n",
    "#     else:\n",
    "#         assert False\n",
    "\n",
    "#     AB = get_prediction_softmax(self, X, token_next)\n",
    "#     X_t1 = X.clone()\n",
    "#     X_t1[0, token1] = self.tokenizer.pad_token_id\n",
    "#     A = self.get_prediction_softmax(X_t1, token_next)\n",
    "\n",
    "#     X_t2 = X.clone()\n",
    "#     X_t2[0,token1] = self.tokenizer.pad_token_id\n",
    "#     B = self.get_prediction_softmax(X_t2, token_next)\n",
    "\n",
    "#     X_t12 = X.clone()\n",
    "#     X_t12[0,token2] = self.tokenizer.pad_token_id\n",
    "#     X_t12[0,token1] = self.tokenizer.pad_token_id\n",
    "#     phi = self.get_prediction_softmax(X_t12, token_next)\n",
    "\n",
    "#     # print(AB, A, B, phi)\n",
    "#     val = AB - A - B + phi\n",
    "\n",
    "\n",
    "#     if self.METHOD == 105:\n",
    "#         val = AB - A - B + phi\n",
    "#         val = torch.divide(torch.linalg.norm(val, dim=1), torch.linalg.norm(AB, dim=1)).cpu()\n",
    "#         res_list = [(1, val.detach(), token_next)]\n",
    "#         val = AB - A - B + phi\n",
    "#         val = torch.divide(torch.linalg.norm(val, dim=1), torch.linalg.norm(AB - phi, dim=1)).cpu()\n",
    "#         res_list.append((2, val.detach(), token_next))\n",
    "#         val = AB - A - B + phi\n",
    "#         val = torch.linalg.norm(val, dim=1).cpu()\n",
    "#         res_list.append((3, val.detach(), token_next))\n",
    "#         val = torch.divide(torch.linalg.norm(AB - A - B, dim=1), torch.linalg.norm(AB, dim=1)).cpu()\n",
    "#         res_list.append((4, val.detach(), token_next))\n",
    "#         return res_list\n",
    "\n",
    "#     assert False\n",
    "\n",
    "#     if self.METHOD == 1:\n",
    "#         val = torch.divide(torch.linalg.norm(val, dim=1), torch.linalg.norm(AB, dim=1)).cpu()\n",
    "#         return val.detach(), token_next\n",
    "#     elif self.METHOD == 2:\n",
    "#         val = torch.divide(torch.linalg.norm(val, dim=1), torch.linalg.norm(AB - phi, dim=1)).cpu()\n",
    "#         return val.detach(), token_next\n",
    "#     elif self.METHOD == 3:\n",
    "#         val = torch.linalg.norm(val, dim=1).cpu()\n",
    "#         return val.detach(), token_next\n",
    "#     elif self.method == 4:\n",
    "#         val = torch.divide(torch.linalg.norm(AB - A - B, dim=1), torch.linalg.norm(AB, dim=1)).cpu()\n",
    "#         return val.detach(), token_next\n",
    "\n",
    "\n",
    "\n",
    "# def calculate_interaction(self, encoded_row, row_number):\n",
    "#     interactions = []\n",
    "#     encoded_len = len(encoded_row)\n",
    "#     for j in range( min(self.SEQ_LEN, encoded_len)):\n",
    "#         probability = 0.05\n",
    "#         if random.random() < probability: \n",
    "#             for k in range(j+1, min(self.SEQ_LEN, encoded_len, j+9)):\n",
    "#                 if j+k >= encoded_len:\n",
    "#                     continue\n",
    "#                 if encoded_row[j] == self.tokenizer.unk_token_id or encoded_row[k] == self.tokenizer.unk_token_id:\n",
    "#                     continue\n",
    "\n",
    "#                 og = encoded_row.clone()\n",
    "#                 og = og.reshape(1, -1)\n",
    "#                 iv = interaction_value_di(self, og, [j, k])\n",
    "#                 interactions.append([iv, abs((j-k)), row_number, j, k])\n",
    "\n",
    "#     return interactions\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "for row_number, row in tqdm.tqdm(enumerate(self.test), total=len(self.test)):\n",
    "    average_distance = []\n",
    "    encoded_row =  self.tokenizer(row, padding=False, is_split_into_words=True, truncation=True, max_length=self.SEQ_LEN, return_tensors ='pt')\n",
    "    g = {}\n",
    "    for ix, el in enumerate(encoded_row.word_ids()):\n",
    "        if el is not None:\n",
    "            if el not in g:\n",
    "                g[el] = []\n",
    "            g[el].append(ix)\n",
    "    mwe = g.values()\n",
    "    encoded_row = encoded_row.input_ids[0]\n",
    "    if self.CUDA:\n",
    "        encoded_row = encoded_row.cuda()\n",
    "\n",
    "    average_distance.extend(self.calculate_interaction(encoded_row, row_number))\n",
    "        \n",
    "    if row_number % 1000 == 0:\n",
    "        print(len(average_distance))\n",
    "        pickle.dump(average_distance, open(f'avg_{self.MODEL_NAME}{suffix}.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"turkish-nlp-suite/Corona-mini\")\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce6daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.sum([ len(dataset['train']['text'][i].split('.')) for i in range(len(dataset['train']['text']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad863e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
